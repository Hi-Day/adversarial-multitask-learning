{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub in /home/dcsmahasiswa1/.local/lib/python3.8/site-packages (0.16.1)\r\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in /home/dcsmahasiswa1/.local/lib/python3.8/site-packages (from tensorflow_hub) (2.15.0)\r\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_hub) (1.24.2)\r\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow_hub) (3.19.6)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 03:54:13.327275: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-27 03:54:13.454644: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-27 03:54:13.985665: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-27 03:54:13.985712: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-27 03:54:13.985717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 03:54:15.157490: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-27 03:54:15.755211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22822 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:37:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n"
     ]
    }
   ],
   "source": [
    "AMAZON = \"amazon\"\n",
    "DSLR = \"dslr\"\n",
    "WEBCAM = \"webcam\"\n",
    "\n",
    "DIR_RESULT = \"result/cf/\"\n",
    "\n",
    "DIR_AMAZON = \"office31/{}\".format(AMAZON)\n",
    "DIR_DSLR = \"office31/{}\".format(DSLR)\n",
    "DIR_WEBCAM = \"office31/{}\".format(WEBCAM)\n",
    "\n",
    "DIR_SOURCE = DIR_AMAZON\n",
    "DIR_TARGET = DIR_WEBCAM\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "dataset_source =  tf.keras.utils.image_dataset_from_directory(\n",
    "                                DIR_SOURCE,\n",
    "                                validation_split=0.2,\n",
    "                                subset=\"training\",\n",
    "                                seed=123,\n",
    "                                image_size=IMAGE_SHAPE,\n",
    "                                batch_size=BATCH_SIZE)\n",
    "\n",
    "dataset_source_val =  tf.keras.utils.image_dataset_from_directory(\n",
    "                                DIR_SOURCE,\n",
    "                                validation_split=0.2,\n",
    "                                subset=\"validation\",\n",
    "                                seed=123,\n",
    "                                image_size=IMAGE_SHAPE,\n",
    "                                batch_size=BATCH_SIZE)\n",
    "\n",
    "dataset_target =  tf.keras.utils.image_dataset_from_directory(\n",
    "                                DIR_TARGET,\n",
    "                                validation_split=0.2,\n",
    "                                subset=\"training\",\n",
    "                                seed=123,\n",
    "                                image_size=IMAGE_SHAPE,\n",
    "                                batch_size=BATCH_SIZE)\n",
    "\n",
    "dataset_target_val =  tf.keras.utils.image_dataset_from_directory(\n",
    "                                DIR_TARGET,\n",
    "                                validation_split=0.2,\n",
    "                                subset=\"validation\",\n",
    "                                seed=123,\n",
    "                                image_size=IMAGE_SHAPE,\n",
    "                                batch_size=BATCH_SIZE)\n",
    "\n",
    "class_names = np.array(dataset_source.class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "dataset_source = dataset_source.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "dataset_source_val = dataset_source_val.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "\n",
    "dataset_target = dataset_target.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "dataset_target_val = dataset_target_val.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "dataset_source = dataset_source.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "dataset_source_val = dataset_source_val.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "dataset_target = dataset_target.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "dataset_target_val = dataset_target_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "inception_v3 = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
    "vit_s16 = \"https://www.kaggle.com/models/spsayakpaul/vision-transformer/frameworks/TensorFlow2/variations/vit-s16-fe/versions/1\"\n",
    "\n",
    "feature_extractor_model = vit_s16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_extractor_layer = hub.KerasLayer(\n",
    "    feature_extractor_model,\n",
    "    input_shape=(224, 224, 3),\n",
    "    trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_14 (KerasLayer)  (None, 384)              21665664  \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 31)                11935     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,677,599\n",
      "Trainable params: 11,935\n",
      "Non-trainable params: 21,665,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_extractor_layer,\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1) # Enable histogram computation for every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 04:19:58.437739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 64 feature_map_count: 3 spatial: 224 224  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 384 input_feature_map_count: 3 layout: OutputInputYX shape: 16 16 }\n",
      "  {zero_padding: 0 0  pad_alignment: default filter_strides: 16 16  dilation_rates: 1 1 }\n",
      "  ... because it uses an identity activation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 0s - loss: 5.9564 - acc: 0.0833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 04:20:05.515811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 60 feature_map_count: 3 spatial: 224 224  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 384 input_feature_map_count: 3 layout: OutputInputYX shape: 16 16 }\n",
      "  {zero_padding: 0 0  pad_alignment: default filter_strides: 16 16  dilation_rates: 1 1 }\n",
      "  ... because it uses an identity activation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 18s 893ms/step - loss: 5.8047 - acc: 0.0881\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 361ms/step - loss: 2.6501 - acc: 0.3286\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 1.0624 - acc: 0.6934\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 3s 368ms/step - loss: 0.4433 - acc: 0.8884\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 370ms/step - loss: 0.2190 - acc: 0.9513\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 3s 352ms/step - loss: 0.1287 - acc: 0.9764\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 3s 358ms/step - loss: 0.0855 - acc: 0.9921\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.0621 - acc: 0.9953\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 358ms/step - loss: 0.0482 - acc: 0.9969\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 3s 367ms/step - loss: 0.0391 - acc: 0.9984\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "history = model.fit(dataset_source,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    callbacks=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1523 - acc: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 04:20:47.727686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 31 feature_map_count: 3 spatial: 224 224  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 384 input_feature_map_count: 3 layout: OutputInputYX shape: 16 16 }\n",
      "  {zero_padding: 0 0  pad_alignment: default filter_strides: 16 16  dilation_rates: 1 1 }\n",
      "  ... because it uses an identity activation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 8s 2s/step - loss: 0.1658 - acc: 0.9560\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3248 - acc: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 04:20:51.869760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 35 feature_map_count: 3 spatial: 224 224  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 384 input_feature_map_count: 3 layout: OutputInputYX shape: 16 16 }\n",
      "  {zero_padding: 0 0  pad_alignment: default filter_strides: 16 16  dilation_rates: 1 1 }\n",
      "  ... because it uses an identity activation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 4s/step - loss: 0.2612 - acc: 0.9293\n"
     ]
    }
   ],
   "source": [
    "source_acc = model.evaluate(dataset_source_val)\n",
    "target_acc = model.evaluate(dataset_target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.1793 - acc: 0.9453"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 04:20:57.355961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 3 spatial: 224 224  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 384 input_feature_map_count: 3 layout: OutputInputYX shape: 16 16 }\n",
      "  {zero_padding: 0 0  pad_alignment: default filter_strides: 16 16  dilation_rates: 1 1 }\n",
      "  ... because it uses an identity activation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 0.1809 - acc: 0.9449\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 3s 477ms/step - loss: 0.0833 - acc: 0.9799\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 3s 470ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 3s 506ms/step - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 3s 453ms/step - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 3s 465ms/step - loss: 0.0102 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset_target,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    callbacks=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1487 - acc: 0.9686\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0620 - acc: 0.9798\n"
     ]
    }
   ],
   "source": [
    "source_acc_ft = model.evaluate(dataset_source_val)\n",
    "target_acc_ft = model.evaluate(dataset_target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955974817276001 0.9292929172515869 0.9685534834861755 0.9797979593276978\n"
     ]
    }
   ],
   "source": [
    "print(source_acc[1],target_acc[1], source_acc_ft[1], target_acc_ft[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mobilenet_v2'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install tensorflow_hub\n",
    "mobilenet_v2.split('/')[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon dslr\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "0.8579040765762329 0.7878788113594055 0.8223801255226135 0.9797979593276978\n",
      "amazon webcam\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "0.8614564538002014 0.7169811129570007 0.8223801255226135 0.9685534834861755\n",
      "dslr amazon\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "0.9797979593276978 0.5914742350578308 0.939393937587738 0.8614564538002014\n",
      "dslr webcam\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "0.939393937587738 0.9308176040649414 0.9797979593276978 0.9811320900917053\n",
      "webcam amazon\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "0.9685534834861755 0.6074600219726562 0.9119496941566467 0.8579040765762329\n",
      "webcam dslr\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "0.9874213933944702 1.0 0.9937106966972351 0.9898989796638489\n",
      "amazon dslr\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "0.8401420712471008 0.7878788113594055 0.8348134756088257 0.9494949579238892\n",
      "amazon webcam\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "0.8436945080757141 0.7735849022865295 0.8312610983848572 0.9685534834861755\n",
      "dslr amazon\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "0.9494949579238892 0.6447601914405823 0.8888888955116272 0.838365912437439\n",
      "dslr webcam\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "0.9595959782600403 0.9308176040649414 0.9797979593276978 0.9685534834861755\n",
      "webcam amazon\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "0.9811320900917053 0.6234458088874817 0.893081784248352 0.845470666885376\n",
      "webcam dslr\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "0.9748427867889404 0.9797979593276978 0.9937106966972351 0.9797979593276978\n",
      "amazon dslr\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 04:57:34.769983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 14 feature_map_count: 3 spatial: 224 224  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 384 input_feature_map_count: 3 layout: OutputInputYX shape: 16 16 }\n",
      "  {zero_padding: 0 0  pad_alignment: default filter_strides: 16 16  dilation_rates: 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2024-02-27 04:58:23.088011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 51 feature_map_count: 3 spatial: 224 224  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 384 input_feature_map_count: 3 layout: OutputInputYX shape: 16 16 }\n",
      "  {zero_padding: 0 0  pad_alignment: default filter_strides: 16 16  dilation_rates: 1 1 }\n",
      "  ... because it uses an identity activation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8596802949905396 0.7979797720909119 0.8401420712471008 0.9595959782600403\n",
      "amazon webcam\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "0.8650088906288147 0.6918238997459412 0.8401420712471008 0.9874213933944702\n",
      "dslr amazon\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "0.8787878751754761 0.5435168743133545 0.9494949579238892 0.8632326722145081\n",
      "dslr webcam\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "0.9292929172515869 0.805031418800354 0.9898989796638489 0.9685534834861755\n",
      "webcam amazon\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "0.9685534834861755 0.577264666557312 0.9371069073677063 0.8685612678527832\n",
      "webcam dslr\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "0.9371069073677063 0.9494949579238892 0.9685534834861755 0.9898989796638489\n",
      "amazon dslr\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "0.8436945080757141 0.7979797720909119 0.8188276886940002 0.9191918969154358\n",
      "amazon webcam\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "0.845470666885376 0.7547169923782349 0.825932502746582 0.9685534834861755\n",
      "dslr amazon\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "0.9494949579238892 0.6216696500778198 0.8888888955116272 0.8525754809379578\n",
      "dslr webcam\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "0.9494949579238892 0.9371069073677063 0.9797979593276978 0.9748427867889404\n",
      "webcam amazon\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "0.9685534834861755 0.6287744045257568 0.9182389974594116 0.838365912437439\n",
      "webcam dslr\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "0.9685534834861755 0.9595959782600403 0.9874213933944702 0.9696969985961914\n",
      "amazon dslr\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "0.8632326722145081 0.7272727489471436 0.8632326722145081 0.9494949579238892\n",
      "amazon webcam\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "0.8579040765762329 0.6792452931404114 0.838365912437439 0.9874213933944702\n",
      "dslr amazon\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "0.9595959782600403 0.6021314263343811 0.9292929172515869 0.8703374862670898\n",
      "dslr webcam\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "0.9595959782600403 0.955974817276001 0.9898989796638489 0.9937106966972351\n",
      "webcam amazon\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 2254 files for training.\n",
      "Found 2817 files belonging to 31 classes.\n",
      "Using 563 files for validation.\n",
      "0.9811320900917053 0.5683836340904236 0.9308176040649414 0.8685612678527832\n",
      "webcam dslr\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 636 files for training.\n",
      "Found 795 files belonging to 31 classes.\n",
      "Using 159 files for validation.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n",
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "0.9811320900917053 0.9797979593276978 0.9937106966972351 0.9898989796638489\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "inception_v3 = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
    "vit_s16 = \"https://www.kaggle.com/models/spsayakpaul/vision-transformer/frameworks/TensorFlow2/variations/vit-s16-fe/versions/1\"\n",
    "efficiennet_v2 = \"https://www.kaggle.com/models/google/efficientnet-v2/frameworks/TensorFlow2/variations/imagenet1k-b0-feature-vector/versions/2\"\n",
    "resnet_50 = \"https://www.kaggle.com/models/tensorflow/resnet-50/frameworks/TensorFlow2/variations/feature-vector/versions/1\"\n",
    "\n",
    "fe_model = [mobilenet_v2, inception_v3, vit_s16, efficiennet_v2, resnet_50]\n",
    "\n",
    "AMAZON = \"amazon\"\n",
    "DSLR = \"dslr\"\n",
    "WEBCAM = \"webcam\"\n",
    "\n",
    "DIR_RESULT = \"result/cf/\"\n",
    "\n",
    "DIR_AMAZON = \"office31/{}\".format(AMAZON)\n",
    "DIR_DSLR = \"office31/{}\".format(DSLR)\n",
    "DIR_WEBCAM = \"office31/{}\".format(WEBCAM)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "model_ = []\n",
    "source = []\n",
    "target = []\n",
    "source_acc_ = []\n",
    "target_acc_ = []\n",
    "training_time_ = []\n",
    "source_acc_ft_ = []\n",
    "target_acc_ft_ = []\n",
    "finetuning_time_ = []\n",
    "####################################################\n",
    "\n",
    "# feature_extractor_model = mobilenet_v2\n",
    "\n",
    "for feature_extractor_model in fe_model:\n",
    "    \n",
    "    \n",
    "    for DIR_SOURCE in [DIR_AMAZON, DIR_DSLR, DIR_WEBCAM]:\n",
    "        for DIR_TARGET in [DIR_AMAZON, DIR_DSLR, DIR_WEBCAM]:\n",
    "\n",
    "            if DIR_SOURCE == DIR_TARGET:\n",
    "                continue\n",
    "                \n",
    "            model_ += [feature_extractor_model.split('/')[5]]\n",
    "            source += [DIR_SOURCE.split('/')[1]] \n",
    "            target += [DIR_TARGET.split('/')[1]]\n",
    "\n",
    "            print(source[-1], target[-1])\n",
    "\n",
    "    # DIR_SOURCE = DIR_AMAZON\n",
    "    # DIR_TARGET = DIR_WEBCAM\n",
    "\n",
    "    ##################################################\n",
    "\n",
    "\n",
    "            dataset_source =  tf.keras.utils.image_dataset_from_directory(\n",
    "                                            DIR_SOURCE,\n",
    "                                            validation_split=0.2,\n",
    "                                            subset=\"training\",\n",
    "                                            seed=123,\n",
    "                                            image_size=IMAGE_SHAPE,\n",
    "                                            batch_size=BATCH_SIZE)\n",
    "\n",
    "            dataset_source_val =  tf.keras.utils.image_dataset_from_directory(\n",
    "                                            DIR_SOURCE,\n",
    "                                            validation_split=0.2,\n",
    "                                            subset=\"validation\",\n",
    "                                            seed=123,\n",
    "                                            image_size=IMAGE_SHAPE,\n",
    "                                            batch_size=BATCH_SIZE)\n",
    "\n",
    "            dataset_target =  tf.keras.utils.image_dataset_from_directory(\n",
    "                                            DIR_TARGET,\n",
    "                                            validation_split=0.2,\n",
    "                                            subset=\"training\",\n",
    "                                            seed=123,\n",
    "                                            image_size=IMAGE_SHAPE,\n",
    "                                            batch_size=BATCH_SIZE)\n",
    "\n",
    "            dataset_target_val =  tf.keras.utils.image_dataset_from_directory(\n",
    "                                            DIR_TARGET,\n",
    "                                            validation_split=0.2,\n",
    "                                            subset=\"validation\",\n",
    "                                            seed=123,\n",
    "                                            image_size=IMAGE_SHAPE,\n",
    "                                            batch_size=BATCH_SIZE)\n",
    "\n",
    "            class_names = np.array(dataset_source.class_names)\n",
    "\n",
    "            normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "            dataset_source = dataset_source.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "            dataset_source_val = dataset_source_val.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "\n",
    "            dataset_target = dataset_target.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "            dataset_target_val = dataset_target_val.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "\n",
    "            AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "            dataset_source = dataset_source.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "            dataset_source_val = dataset_source_val.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "            dataset_target = dataset_target.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "            dataset_target_val = dataset_target_val.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "            feature_extractor_layer = hub.KerasLayer(\n",
    "                feature_extractor_model,\n",
    "                input_shape=(224, 224, 3),\n",
    "                trainable=False)\n",
    "\n",
    "            num_classes = len(class_names)\n",
    "\n",
    "            model = tf.keras.Sequential([\n",
    "              feature_extractor_layer,\n",
    "              tf.keras.layers.Dense(num_classes)\n",
    "            ])\n",
    "\n",
    "            model.compile(\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['acc'])\n",
    "\n",
    "            NUM_EPOCHS = 10\n",
    "\n",
    "            # training \n",
    "            ###############################################################\n",
    "            start_time = time.time()\n",
    "            history = model.fit(dataset_source,\n",
    "                                epochs=NUM_EPOCHS,\n",
    "                               verbose=0)\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            training_time_ += [elapsed_time]\n",
    "\n",
    "            source_acc = model.evaluate(dataset_source_val, verbose=0)\n",
    "            target_acc = model.evaluate(dataset_target_val, verbose=0)\n",
    "            ###############################################################\n",
    "\n",
    "            #fine tuning\n",
    "            ###############################################################\n",
    "            start_time = time.time()\n",
    "            history = model.fit(dataset_target,\n",
    "                                epochs=NUM_EPOCHS,\n",
    "                                verbose=0)\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            finetuning_time_ += [elapsed_time]\n",
    "\n",
    "            source_acc_ft = model.evaluate(dataset_source_val, verbose=0)\n",
    "            target_acc_ft = model.evaluate(dataset_target_val, verbose=0)\n",
    "            ###############################################################\n",
    "\n",
    "            source_acc_ += [source_acc[1]]\n",
    "            target_acc_ += [target_acc[1]]\n",
    "            source_acc_ft_ += [source_acc_ft[1]]\n",
    "            target_acc_ft_ += [target_acc_ft[1]]\n",
    "\n",
    "            print(source_acc[1],target_acc[1], source_acc_ft[1], target_acc_ft[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ = ['mobilenet_v2']*6 + ['inception_v3']*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'model': model_,\n",
    "     'source': source, \n",
    "     'target': target, \n",
    "     'source_acc': source_acc_,\n",
    "     'target_acc': target_acc_,\n",
    "     'source_acc_ft':source_acc_ft_,\n",
    "     'target_acc_ft': target_acc_ft_,\n",
    "     'training_time': training_time_,\n",
    "     'finetuning_time': finetuning_time_}\n",
    "\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['catastrophic forgetting'] = df['source_acc_ft'] - df['source_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_acc</th>\n",
       "      <th>target_acc</th>\n",
       "      <th>source_acc_ft</th>\n",
       "      <th>target_acc_ft</th>\n",
       "      <th>training_time</th>\n",
       "      <th>finetuning_time</th>\n",
       "      <th>catastrophic forgetting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>amazon</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.857904</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.822380</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>20.085061</td>\n",
       "      <td>3.320356</td>\n",
       "      <td>-0.035524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>amazon</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.861456</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.822380</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>18.317163</td>\n",
       "      <td>4.713650</td>\n",
       "      <td>-0.039076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>dslr</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.591474</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.861456</td>\n",
       "      <td>5.416722</td>\n",
       "      <td>15.983193</td>\n",
       "      <td>-0.040404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>dslr</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.930818</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>5.632095</td>\n",
       "      <td>4.717780</td>\n",
       "      <td>0.040404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>webcam</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.607460</td>\n",
       "      <td>0.911950</td>\n",
       "      <td>0.857904</td>\n",
       "      <td>6.923398</td>\n",
       "      <td>15.200419</td>\n",
       "      <td>-0.056604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>webcam</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>6.703024</td>\n",
       "      <td>3.112073</td>\n",
       "      <td>0.006289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>amazon</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.840142</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.834813</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>25.773040</td>\n",
       "      <td>4.370522</td>\n",
       "      <td>-0.005329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>amazon</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.843695</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.831261</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>26.439016</td>\n",
       "      <td>6.580364</td>\n",
       "      <td>-0.012433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>dslr</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.644760</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.838366</td>\n",
       "      <td>7.696542</td>\n",
       "      <td>22.495136</td>\n",
       "      <td>-0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>dslr</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.930818</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>7.795503</td>\n",
       "      <td>6.478355</td>\n",
       "      <td>0.020202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>webcam</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.623446</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.845471</td>\n",
       "      <td>9.693835</td>\n",
       "      <td>22.394017</td>\n",
       "      <td>-0.088050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>webcam</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>9.981272</td>\n",
       "      <td>4.327161</td>\n",
       "      <td>0.018868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vision-transformer</td>\n",
       "      <td>amazon</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.859680</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.840142</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>54.322179</td>\n",
       "      <td>10.979807</td>\n",
       "      <td>-0.019538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vision-transformer</td>\n",
       "      <td>amazon</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.865009</td>\n",
       "      <td>0.691824</td>\n",
       "      <td>0.840142</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>53.061470</td>\n",
       "      <td>15.425504</td>\n",
       "      <td>-0.024867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vision-transformer</td>\n",
       "      <td>dslr</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.543517</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.863233</td>\n",
       "      <td>16.226757</td>\n",
       "      <td>47.269063</td>\n",
       "      <td>0.070707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vision-transformer</td>\n",
       "      <td>dslr</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.805031</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>16.231164</td>\n",
       "      <td>15.310932</td>\n",
       "      <td>0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vision-transformer</td>\n",
       "      <td>webcam</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.577265</td>\n",
       "      <td>0.937107</td>\n",
       "      <td>0.868561</td>\n",
       "      <td>20.631936</td>\n",
       "      <td>47.871440</td>\n",
       "      <td>-0.031447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vision-transformer</td>\n",
       "      <td>webcam</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.937107</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>20.746079</td>\n",
       "      <td>10.889518</td>\n",
       "      <td>0.031447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>efficientnet-v2</td>\n",
       "      <td>amazon</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.843695</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.818828</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>23.557296</td>\n",
       "      <td>3.920681</td>\n",
       "      <td>-0.024867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>efficientnet-v2</td>\n",
       "      <td>amazon</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.845471</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.825933</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>24.752309</td>\n",
       "      <td>5.648568</td>\n",
       "      <td>-0.019538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>efficientnet-v2</td>\n",
       "      <td>dslr</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.621670</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.852575</td>\n",
       "      <td>7.921675</td>\n",
       "      <td>18.422936</td>\n",
       "      <td>-0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>efficientnet-v2</td>\n",
       "      <td>dslr</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.937107</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>9.638789</td>\n",
       "      <td>5.530922</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>efficientnet-v2</td>\n",
       "      <td>webcam</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.628774</td>\n",
       "      <td>0.918239</td>\n",
       "      <td>0.838366</td>\n",
       "      <td>9.851554</td>\n",
       "      <td>18.850590</td>\n",
       "      <td>-0.050314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>efficientnet-v2</td>\n",
       "      <td>webcam</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>12.532682</td>\n",
       "      <td>3.719240</td>\n",
       "      <td>0.018868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>resnet-50</td>\n",
       "      <td>amazon</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.863233</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.863233</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>35.900593</td>\n",
       "      <td>6.229708</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>resnet-50</td>\n",
       "      <td>amazon</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.857904</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.838366</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>34.947505</td>\n",
       "      <td>9.652485</td>\n",
       "      <td>-0.019538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>resnet-50</td>\n",
       "      <td>dslr</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.602131</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.870337</td>\n",
       "      <td>9.514238</td>\n",
       "      <td>31.184992</td>\n",
       "      <td>-0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>resnet-50</td>\n",
       "      <td>dslr</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>9.754992</td>\n",
       "      <td>9.036502</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>resnet-50</td>\n",
       "      <td>webcam</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.568384</td>\n",
       "      <td>0.930818</td>\n",
       "      <td>0.868561</td>\n",
       "      <td>12.753717</td>\n",
       "      <td>31.514989</td>\n",
       "      <td>-0.050314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>resnet-50</td>\n",
       "      <td>webcam</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>12.927355</td>\n",
       "      <td>5.952947</td>\n",
       "      <td>0.012579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  source  target  source_acc  target_acc  source_acc_ft  \\\n",
       "0         mobilenet_v2  amazon    dslr    0.857904    0.787879       0.822380   \n",
       "1         mobilenet_v2  amazon  webcam    0.861456    0.716981       0.822380   \n",
       "2         mobilenet_v2    dslr  amazon    0.979798    0.591474       0.939394   \n",
       "3         mobilenet_v2    dslr  webcam    0.939394    0.930818       0.979798   \n",
       "4         mobilenet_v2  webcam  amazon    0.968553    0.607460       0.911950   \n",
       "5         mobilenet_v2  webcam    dslr    0.987421    1.000000       0.993711   \n",
       "6         inception_v3  amazon    dslr    0.840142    0.787879       0.834813   \n",
       "7         inception_v3  amazon  webcam    0.843695    0.773585       0.831261   \n",
       "8         inception_v3    dslr  amazon    0.949495    0.644760       0.888889   \n",
       "9         inception_v3    dslr  webcam    0.959596    0.930818       0.979798   \n",
       "10        inception_v3  webcam  amazon    0.981132    0.623446       0.893082   \n",
       "11        inception_v3  webcam    dslr    0.974843    0.979798       0.993711   \n",
       "12  vision-transformer  amazon    dslr    0.859680    0.797980       0.840142   \n",
       "13  vision-transformer  amazon  webcam    0.865009    0.691824       0.840142   \n",
       "14  vision-transformer    dslr  amazon    0.878788    0.543517       0.949495   \n",
       "15  vision-transformer    dslr  webcam    0.929293    0.805031       0.989899   \n",
       "16  vision-transformer  webcam  amazon    0.968553    0.577265       0.937107   \n",
       "17  vision-transformer  webcam    dslr    0.937107    0.949495       0.968553   \n",
       "18     efficientnet-v2  amazon    dslr    0.843695    0.797980       0.818828   \n",
       "19     efficientnet-v2  amazon  webcam    0.845471    0.754717       0.825933   \n",
       "20     efficientnet-v2    dslr  amazon    0.949495    0.621670       0.888889   \n",
       "21     efficientnet-v2    dslr  webcam    0.949495    0.937107       0.979798   \n",
       "22     efficientnet-v2  webcam  amazon    0.968553    0.628774       0.918239   \n",
       "23     efficientnet-v2  webcam    dslr    0.968553    0.959596       0.987421   \n",
       "24           resnet-50  amazon    dslr    0.863233    0.727273       0.863233   \n",
       "25           resnet-50  amazon  webcam    0.857904    0.679245       0.838366   \n",
       "26           resnet-50    dslr  amazon    0.959596    0.602131       0.929293   \n",
       "27           resnet-50    dslr  webcam    0.959596    0.955975       0.989899   \n",
       "28           resnet-50  webcam  amazon    0.981132    0.568384       0.930818   \n",
       "29           resnet-50  webcam    dslr    0.981132    0.979798       0.993711   \n",
       "\n",
       "    target_acc_ft  training_time  finetuning_time  catastrophic forgetting  \n",
       "0        0.979798      20.085061         3.320356                -0.035524  \n",
       "1        0.968553      18.317163         4.713650                -0.039076  \n",
       "2        0.861456       5.416722        15.983193                -0.040404  \n",
       "3        0.981132       5.632095         4.717780                 0.040404  \n",
       "4        0.857904       6.923398        15.200419                -0.056604  \n",
       "5        0.989899       6.703024         3.112073                 0.006289  \n",
       "6        0.949495      25.773040         4.370522                -0.005329  \n",
       "7        0.968553      26.439016         6.580364                -0.012433  \n",
       "8        0.838366       7.696542        22.495136                -0.060606  \n",
       "9        0.968553       7.795503         6.478355                 0.020202  \n",
       "10       0.845471       9.693835        22.394017                -0.088050  \n",
       "11       0.979798       9.981272         4.327161                 0.018868  \n",
       "12       0.959596      54.322179        10.979807                -0.019538  \n",
       "13       0.987421      53.061470        15.425504                -0.024867  \n",
       "14       0.863233      16.226757        47.269063                 0.070707  \n",
       "15       0.968553      16.231164        15.310932                 0.060606  \n",
       "16       0.868561      20.631936        47.871440                -0.031447  \n",
       "17       0.989899      20.746079        10.889518                 0.031447  \n",
       "18       0.919192      23.557296         3.920681                -0.024867  \n",
       "19       0.968553      24.752309         5.648568                -0.019538  \n",
       "20       0.852575       7.921675        18.422936                -0.060606  \n",
       "21       0.974843       9.638789         5.530922                 0.030303  \n",
       "22       0.838366       9.851554        18.850590                -0.050314  \n",
       "23       0.969697      12.532682         3.719240                 0.018868  \n",
       "24       0.949495      35.900593         6.229708                 0.000000  \n",
       "25       0.987421      34.947505         9.652485                -0.019538  \n",
       "26       0.870337       9.514238        31.184992                -0.030303  \n",
       "27       0.993711       9.754992         9.036502                 0.030303  \n",
       "28       0.868561      12.753717        31.514989                -0.050314  \n",
       "29       0.989899      12.927355         5.952947                 0.012579  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_acc</th>\n",
       "      <th>target_acc</th>\n",
       "      <th>source_acc_ft</th>\n",
       "      <th>target_acc_ft</th>\n",
       "      <th>training_time</th>\n",
       "      <th>finetuning_time</th>\n",
       "      <th>catastrophic forgetting</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>efficientnet-v2</th>\n",
       "      <td>0.920877</td>\n",
       "      <td>0.783307</td>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.920538</td>\n",
       "      <td>14.709051</td>\n",
       "      <td>9.348823</td>\n",
       "      <td>-0.017692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inception_v3</th>\n",
       "      <td>0.924817</td>\n",
       "      <td>0.790048</td>\n",
       "      <td>0.903592</td>\n",
       "      <td>0.925039</td>\n",
       "      <td>14.563201</td>\n",
       "      <td>11.107593</td>\n",
       "      <td>-0.021225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobilenet_v2</th>\n",
       "      <td>0.932421</td>\n",
       "      <td>0.772435</td>\n",
       "      <td>0.911602</td>\n",
       "      <td>0.939791</td>\n",
       "      <td>10.512910</td>\n",
       "      <td>7.841245</td>\n",
       "      <td>-0.020819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet-50</th>\n",
       "      <td>0.933765</td>\n",
       "      <td>0.752134</td>\n",
       "      <td>0.924220</td>\n",
       "      <td>0.943237</td>\n",
       "      <td>19.299733</td>\n",
       "      <td>15.595271</td>\n",
       "      <td>-0.009546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vision-transformer</th>\n",
       "      <td>0.906405</td>\n",
       "      <td>0.727519</td>\n",
       "      <td>0.920890</td>\n",
       "      <td>0.939544</td>\n",
       "      <td>30.203264</td>\n",
       "      <td>24.624377</td>\n",
       "      <td>0.014485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source_acc  target_acc  source_acc_ft  target_acc_ft  \\\n",
       "model                                                                      \n",
       "efficientnet-v2       0.920877    0.783307       0.903185       0.920538   \n",
       "inception_v3          0.924817    0.790048       0.903592       0.925039   \n",
       "mobilenet_v2          0.932421    0.772435       0.911602       0.939791   \n",
       "resnet-50             0.933765    0.752134       0.924220       0.943237   \n",
       "vision-transformer    0.906405    0.727519       0.920890       0.939544   \n",
       "\n",
       "                    training_time  finetuning_time  catastrophic forgetting  \n",
       "model                                                                        \n",
       "efficientnet-v2         14.709051         9.348823                -0.017692  \n",
       "inception_v3            14.563201        11.107593                -0.021225  \n",
       "mobilenet_v2            10.512910         7.841245                -0.020819  \n",
       "resnet-50               19.299733        15.595271                -0.009546  \n",
       "vision-transformer      30.203264        24.624377                 0.014485  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['source','target']).groupby('model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>source_acc</th>\n",
       "      <th>target_acc</th>\n",
       "      <th>source_acc_ft</th>\n",
       "      <th>target_acc_ft</th>\n",
       "      <th>training_time</th>\n",
       "      <th>finetuning_time</th>\n",
       "      <th>catastrophic forgetting</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">amazon</th>\n",
       "      <th>dslr</th>\n",
       "      <td>0.852931</td>\n",
       "      <td>0.779798</td>\n",
       "      <td>0.835879</td>\n",
       "      <td>0.951515</td>\n",
       "      <td>31.927634</td>\n",
       "      <td>5.764215</td>\n",
       "      <td>-0.017052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webcam</th>\n",
       "      <td>0.854707</td>\n",
       "      <td>0.723270</td>\n",
       "      <td>0.831616</td>\n",
       "      <td>0.976101</td>\n",
       "      <td>31.503492</td>\n",
       "      <td>8.404114</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dslr</th>\n",
       "      <th>amazon</th>\n",
       "      <td>0.943434</td>\n",
       "      <td>0.600710</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.857194</td>\n",
       "      <td>9.355187</td>\n",
       "      <td>27.071064</td>\n",
       "      <td>-0.024242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webcam</th>\n",
       "      <td>0.947475</td>\n",
       "      <td>0.911950</td>\n",
       "      <td>0.983838</td>\n",
       "      <td>0.977359</td>\n",
       "      <td>9.810508</td>\n",
       "      <td>8.214898</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">webcam</th>\n",
       "      <th>amazon</th>\n",
       "      <td>0.973585</td>\n",
       "      <td>0.601066</td>\n",
       "      <td>0.918239</td>\n",
       "      <td>0.855773</td>\n",
       "      <td>11.970888</td>\n",
       "      <td>27.166291</td>\n",
       "      <td>-0.055346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dslr</th>\n",
       "      <td>0.969811</td>\n",
       "      <td>0.973737</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>0.983838</td>\n",
       "      <td>12.578082</td>\n",
       "      <td>5.600188</td>\n",
       "      <td>0.017610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source_acc  target_acc  source_acc_ft  target_acc_ft  \\\n",
       "source target                                                         \n",
       "amazon dslr      0.852931    0.779798       0.835879       0.951515   \n",
       "       webcam    0.854707    0.723270       0.831616       0.976101   \n",
       "dslr   amazon    0.943434    0.600710       0.919192       0.857194   \n",
       "       webcam    0.947475    0.911950       0.983838       0.977359   \n",
       "webcam amazon    0.973585    0.601066       0.918239       0.855773   \n",
       "       dslr      0.969811    0.973737       0.987421       0.983838   \n",
       "\n",
       "               training_time  finetuning_time  catastrophic forgetting  \n",
       "source target                                                           \n",
       "amazon dslr        31.927634         5.764215                -0.017052  \n",
       "       webcam      31.503492         8.404114                -0.023091  \n",
       "dslr   amazon       9.355187        27.071064                -0.024242  \n",
       "       webcam       9.810508         8.214898                 0.036364  \n",
       "webcam amazon      11.970888        27.166291                -0.055346  \n",
       "       dslr        12.578082         5.600188                 0.017610  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['model']).groupby(['source','target']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_acc</th>\n",
       "      <th>target_acc</th>\n",
       "      <th>source_acc_ft</th>\n",
       "      <th>target_acc_ft</th>\n",
       "      <th>training_time</th>\n",
       "      <th>finetuning_time</th>\n",
       "      <th>catastrophic forgetting</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>efficientnet-v2</th>\n",
       "      <td>0.915153</td>\n",
       "      <td>0.752547</td>\n",
       "      <td>0.887862</td>\n",
       "      <td>0.909677</td>\n",
       "      <td>15.723103</td>\n",
       "      <td>10.112403</td>\n",
       "      <td>-0.027292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inception_v3</th>\n",
       "      <td>0.917861</td>\n",
       "      <td>0.761894</td>\n",
       "      <td>0.888351</td>\n",
       "      <td>0.916337</td>\n",
       "      <td>15.916741</td>\n",
       "      <td>12.033440</td>\n",
       "      <td>-0.029510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobilenet_v2</th>\n",
       "      <td>0.931027</td>\n",
       "      <td>0.740759</td>\n",
       "      <td>0.897963</td>\n",
       "      <td>0.931522</td>\n",
       "      <td>11.489073</td>\n",
       "      <td>8.465938</td>\n",
       "      <td>-0.033064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet-50</th>\n",
       "      <td>0.928599</td>\n",
       "      <td>0.711366</td>\n",
       "      <td>0.911084</td>\n",
       "      <td>0.933143</td>\n",
       "      <td>21.208681</td>\n",
       "      <td>16.907024</td>\n",
       "      <td>-0.017515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vision-transformer</th>\n",
       "      <td>0.901827</td>\n",
       "      <td>0.712016</td>\n",
       "      <td>0.907088</td>\n",
       "      <td>0.933742</td>\n",
       "      <td>32.997684</td>\n",
       "      <td>26.487067</td>\n",
       "      <td>0.005260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source_acc  target_acc  source_acc_ft  target_acc_ft  \\\n",
       "model                                                                      \n",
       "efficientnet-v2       0.915153    0.752547       0.887862       0.909677   \n",
       "inception_v3          0.917861    0.761894       0.888351       0.916337   \n",
       "mobilenet_v2          0.931027    0.740759       0.897963       0.931522   \n",
       "resnet-50             0.928599    0.711366       0.911084       0.933143   \n",
       "vision-transformer    0.901827    0.712016       0.907088       0.933742   \n",
       "\n",
       "                    training_time  finetuning_time  catastrophic forgetting  \n",
       "model                                                                        \n",
       "efficientnet-v2         15.723103        10.112403                -0.027292  \n",
       "inception_v3            15.916741        12.033440                -0.029510  \n",
       "mobilenet_v2            11.489073         8.465938                -0.033064  \n",
       "resnet-50               21.208681        16.907024                -0.017515  \n",
       "vision-transformer      32.997684        26.487067                 0.005260  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df[(df['source'] == 'dslr') & (df['target'] == 'webcam')].index).drop(columns=['source','target']).groupby('model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_acc</th>\n",
       "      <th>target_acc</th>\n",
       "      <th>source_acc_ft</th>\n",
       "      <th>target_acc_ft</th>\n",
       "      <th>training_time</th>\n",
       "      <th>finetuning_time</th>\n",
       "      <th>catastrophic forgetting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>amazon</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.857904</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.822380</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>20.085061</td>\n",
       "      <td>3.320356</td>\n",
       "      <td>-0.035524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>amazon</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.861456</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.822380</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>18.317163</td>\n",
       "      <td>4.713650</td>\n",
       "      <td>-0.039076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>dslr</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.591474</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.861456</td>\n",
       "      <td>5.416722</td>\n",
       "      <td>15.983193</td>\n",
       "      <td>-0.040404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>dslr</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.930818</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>5.632095</td>\n",
       "      <td>4.717780</td>\n",
       "      <td>0.040404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>webcam</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.607460</td>\n",
       "      <td>0.911950</td>\n",
       "      <td>0.857904</td>\n",
       "      <td>6.923398</td>\n",
       "      <td>15.200419</td>\n",
       "      <td>-0.056604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>webcam</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>6.703024</td>\n",
       "      <td>3.112073</td>\n",
       "      <td>0.006289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>amazon</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.840142</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.834813</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>25.773040</td>\n",
       "      <td>4.370522</td>\n",
       "      <td>-0.005329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>amazon</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.843695</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.831261</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>26.439016</td>\n",
       "      <td>6.580364</td>\n",
       "      <td>-0.012433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>dslr</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.644760</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.838366</td>\n",
       "      <td>7.696542</td>\n",
       "      <td>22.495136</td>\n",
       "      <td>-0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>dslr</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.930818</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>7.795503</td>\n",
       "      <td>6.478355</td>\n",
       "      <td>0.020202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>webcam</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.623446</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.845471</td>\n",
       "      <td>9.693835</td>\n",
       "      <td>22.394017</td>\n",
       "      <td>-0.088050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>webcam</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>9.981272</td>\n",
       "      <td>4.327161</td>\n",
       "      <td>0.018868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vision-transformer</td>\n",
       "      <td>amazon</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.859680</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.840142</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>54.322179</td>\n",
       "      <td>10.979807</td>\n",
       "      <td>-0.019538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vision-transformer</td>\n",
       "      <td>amazon</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.865009</td>\n",
       "      <td>0.691824</td>\n",
       "      <td>0.840142</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>53.061470</td>\n",
       "      <td>15.425504</td>\n",
       "      <td>-0.024867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vision-transformer</td>\n",
       "      <td>dslr</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.543517</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.863233</td>\n",
       "      <td>16.226757</td>\n",
       "      <td>47.269063</td>\n",
       "      <td>0.070707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vision-transformer</td>\n",
       "      <td>dslr</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.805031</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>16.231164</td>\n",
       "      <td>15.310932</td>\n",
       "      <td>0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vision-transformer</td>\n",
       "      <td>webcam</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.577265</td>\n",
       "      <td>0.937107</td>\n",
       "      <td>0.868561</td>\n",
       "      <td>20.631936</td>\n",
       "      <td>47.871440</td>\n",
       "      <td>-0.031447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vision-transformer</td>\n",
       "      <td>webcam</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.937107</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>20.746079</td>\n",
       "      <td>10.889518</td>\n",
       "      <td>0.031447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>efficientnet-v2</td>\n",
       "      <td>amazon</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.843695</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.818828</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>23.557296</td>\n",
       "      <td>3.920681</td>\n",
       "      <td>-0.024867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>efficientnet-v2</td>\n",
       "      <td>amazon</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.845471</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.825933</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>24.752309</td>\n",
       "      <td>5.648568</td>\n",
       "      <td>-0.019538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>efficientnet-v2</td>\n",
       "      <td>dslr</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.621670</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.852575</td>\n",
       "      <td>7.921675</td>\n",
       "      <td>18.422936</td>\n",
       "      <td>-0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>efficientnet-v2</td>\n",
       "      <td>dslr</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.937107</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>9.638789</td>\n",
       "      <td>5.530922</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>efficientnet-v2</td>\n",
       "      <td>webcam</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.628774</td>\n",
       "      <td>0.918239</td>\n",
       "      <td>0.838366</td>\n",
       "      <td>9.851554</td>\n",
       "      <td>18.850590</td>\n",
       "      <td>-0.050314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>efficientnet-v2</td>\n",
       "      <td>webcam</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>12.532682</td>\n",
       "      <td>3.719240</td>\n",
       "      <td>0.018868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>resnet-50</td>\n",
       "      <td>amazon</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.863233</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.863233</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>35.900593</td>\n",
       "      <td>6.229708</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>resnet-50</td>\n",
       "      <td>amazon</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.857904</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.838366</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>34.947505</td>\n",
       "      <td>9.652485</td>\n",
       "      <td>-0.019538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>resnet-50</td>\n",
       "      <td>dslr</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.602131</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.870337</td>\n",
       "      <td>9.514238</td>\n",
       "      <td>31.184992</td>\n",
       "      <td>-0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>resnet-50</td>\n",
       "      <td>dslr</td>\n",
       "      <td>webcam</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>9.754992</td>\n",
       "      <td>9.036502</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>resnet-50</td>\n",
       "      <td>webcam</td>\n",
       "      <td>amazon</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.568384</td>\n",
       "      <td>0.930818</td>\n",
       "      <td>0.868561</td>\n",
       "      <td>12.753717</td>\n",
       "      <td>31.514989</td>\n",
       "      <td>-0.050314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>resnet-50</td>\n",
       "      <td>webcam</td>\n",
       "      <td>dslr</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>12.927355</td>\n",
       "      <td>5.952947</td>\n",
       "      <td>0.012579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  source  target  source_acc  target_acc  source_acc_ft  \\\n",
       "0         mobilenet_v2  amazon    dslr    0.857904    0.787879       0.822380   \n",
       "1         mobilenet_v2  amazon  webcam    0.861456    0.716981       0.822380   \n",
       "2         mobilenet_v2    dslr  amazon    0.979798    0.591474       0.939394   \n",
       "3         mobilenet_v2    dslr  webcam    0.939394    0.930818       0.979798   \n",
       "4         mobilenet_v2  webcam  amazon    0.968553    0.607460       0.911950   \n",
       "5         mobilenet_v2  webcam    dslr    0.987421    1.000000       0.993711   \n",
       "6         inception_v3  amazon    dslr    0.840142    0.787879       0.834813   \n",
       "7         inception_v3  amazon  webcam    0.843695    0.773585       0.831261   \n",
       "8         inception_v3    dslr  amazon    0.949495    0.644760       0.888889   \n",
       "9         inception_v3    dslr  webcam    0.959596    0.930818       0.979798   \n",
       "10        inception_v3  webcam  amazon    0.981132    0.623446       0.893082   \n",
       "11        inception_v3  webcam    dslr    0.974843    0.979798       0.993711   \n",
       "12  vision-transformer  amazon    dslr    0.859680    0.797980       0.840142   \n",
       "13  vision-transformer  amazon  webcam    0.865009    0.691824       0.840142   \n",
       "14  vision-transformer    dslr  amazon    0.878788    0.543517       0.949495   \n",
       "15  vision-transformer    dslr  webcam    0.929293    0.805031       0.989899   \n",
       "16  vision-transformer  webcam  amazon    0.968553    0.577265       0.937107   \n",
       "17  vision-transformer  webcam    dslr    0.937107    0.949495       0.968553   \n",
       "18     efficientnet-v2  amazon    dslr    0.843695    0.797980       0.818828   \n",
       "19     efficientnet-v2  amazon  webcam    0.845471    0.754717       0.825933   \n",
       "20     efficientnet-v2    dslr  amazon    0.949495    0.621670       0.888889   \n",
       "21     efficientnet-v2    dslr  webcam    0.949495    0.937107       0.979798   \n",
       "22     efficientnet-v2  webcam  amazon    0.968553    0.628774       0.918239   \n",
       "23     efficientnet-v2  webcam    dslr    0.968553    0.959596       0.987421   \n",
       "24           resnet-50  amazon    dslr    0.863233    0.727273       0.863233   \n",
       "25           resnet-50  amazon  webcam    0.857904    0.679245       0.838366   \n",
       "26           resnet-50    dslr  amazon    0.959596    0.602131       0.929293   \n",
       "27           resnet-50    dslr  webcam    0.959596    0.955975       0.989899   \n",
       "28           resnet-50  webcam  amazon    0.981132    0.568384       0.930818   \n",
       "29           resnet-50  webcam    dslr    0.981132    0.979798       0.993711   \n",
       "\n",
       "    target_acc_ft  training_time  finetuning_time  catastrophic forgetting  \n",
       "0        0.979798      20.085061         3.320356                -0.035524  \n",
       "1        0.968553      18.317163         4.713650                -0.039076  \n",
       "2        0.861456       5.416722        15.983193                -0.040404  \n",
       "3        0.981132       5.632095         4.717780                 0.040404  \n",
       "4        0.857904       6.923398        15.200419                -0.056604  \n",
       "5        0.989899       6.703024         3.112073                 0.006289  \n",
       "6        0.949495      25.773040         4.370522                -0.005329  \n",
       "7        0.968553      26.439016         6.580364                -0.012433  \n",
       "8        0.838366       7.696542        22.495136                -0.060606  \n",
       "9        0.968553       7.795503         6.478355                 0.020202  \n",
       "10       0.845471       9.693835        22.394017                -0.088050  \n",
       "11       0.979798       9.981272         4.327161                 0.018868  \n",
       "12       0.959596      54.322179        10.979807                -0.019538  \n",
       "13       0.987421      53.061470        15.425504                -0.024867  \n",
       "14       0.863233      16.226757        47.269063                 0.070707  \n",
       "15       0.968553      16.231164        15.310932                 0.060606  \n",
       "16       0.868561      20.631936        47.871440                -0.031447  \n",
       "17       0.989899      20.746079        10.889518                 0.031447  \n",
       "18       0.919192      23.557296         3.920681                -0.024867  \n",
       "19       0.968553      24.752309         5.648568                -0.019538  \n",
       "20       0.852575       7.921675        18.422936                -0.060606  \n",
       "21       0.974843       9.638789         5.530922                 0.030303  \n",
       "22       0.838366       9.851554        18.850590                -0.050314  \n",
       "23       0.969697      12.532682         3.719240                 0.018868  \n",
       "24       0.949495      35.900593         6.229708                 0.000000  \n",
       "25       0.987421      34.947505         9.652485                -0.019538  \n",
       "26       0.870337       9.514238        31.184992                -0.030303  \n",
       "27       0.993711       9.754992         9.036502                 0.030303  \n",
       "28       0.868561      12.753717        31.514989                -0.050314  \n",
       "29       0.989899      12.927355         5.952947                 0.012579  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('catastrophic_forgetting_office31.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "beginner.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
