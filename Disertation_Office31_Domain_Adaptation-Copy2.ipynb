{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0JHVsAKBu1e"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YO7tYct5Bqcc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 03:11:09.479909: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 03:11:09.605740: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-22 03:11:10.136202: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-22 03:11:10.136268: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-22 03:11:10.136273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import clone_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PWAyTR8EVA-f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 files belonging to 31 classes.\n",
      "Using 399 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 03:11:10.947145: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 03:11:11.545122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22822 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:37:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 files belonging to 31 classes.\n",
      "Using 99 files for validation.\n",
      "Found 795 files belonging to 31 classes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "DIR_AMAZON = \"office31/amazon\"\n",
    "DIR_DSLR = \"office31/dslr\"\n",
    "DIR_WEBCAM = \"office31/webcam\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "IMG_DIM = 3\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "# W_CATEGORICAL = 0.1\n",
    "# W_ADVERSARIAL = 0\n",
    "# W_DOMAIN      = 1\n",
    "\n",
    "SOURCE = DIR_DSLR\n",
    "TARGET = DIR_WEBCAM\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "dataset_source = tf.keras.utils.image_dataset_from_directory(\n",
    "  SOURCE,                                                     # change DIR according to the dataset\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "dataset_source_val = tf.keras.utils.image_dataset_from_directory(\n",
    "  SOURCE,                                                     # change DIR according to the dataset\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "dataset_target = tf.keras.utils.image_dataset_from_directory(\n",
    "  TARGET,                                                     # change DIR according to the dataset\n",
    "  seed=123,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "dataset_source = dataset_source.map(lambda x, y: (normalization_layer(x), y))\n",
    "dataset_source_val = dataset_source_val.map(lambda x, y: (normalization_layer(x), y))\n",
    "dataset_target = dataset_target.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "dataset = tf.data.Dataset.zip((dataset_source, dataset_source_val, dataset_target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6tnywK2AgHV"
   },
   "source": [
    "# Preparation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_d6iVg1TKomt"
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def grad_reverse(x):\n",
    "    y = tf.identity(x)\n",
    "    def custom_grad(dy):\n",
    "        return -dy\n",
    "    return y, custom_grad\n",
    "\n",
    "class GradReverse(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @tf.function\n",
    "def train_step(real_images, real_label, test_images, test_label, target_images, target_label):\n",
    "# def train_step(d_optimizer, g_optimizer, c_optimizer, fe_optimizer, domain_optimizer, feature_extractor, categorical_classifier, domain_classifier, generator, discriminator, real_images, real_label, test_images, test_label, target_images, target_label):\n",
    "    # Sample random points in the latent space\n",
    "    random_latent_vectors = tf.random.normal(shape=(BATCH_SIZE, latent_dim))\n",
    "    # Decode them to fake images\n",
    "    generated_images = generator(random_latent_vectors)\n",
    "    # Combine them with real images\n",
    "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "    # Assemble labels discriminating real from fake images\n",
    "    labels = tf.concat(\n",
    "        [tf.ones((BATCH_SIZE, 1)), tf.zeros((real_images.shape[0], 1))], axis=0\n",
    "    )\n",
    "    # Add random noise to the labels - important trick!\n",
    "    labels += 0.05 * tf.random.uniform(labels.shape)\n",
    "\n",
    "    combined_domain = tf.concat([target_images, real_images], axis=0)\n",
    "\n",
    "    # Assemble labels classifying target from source images\n",
    "    labels_domain = tf.concat(\n",
    "        [tf.ones((target_images.shape[0], 1)), tf.zeros((real_images.shape[0], 1))], axis=0\n",
    "    )\n",
    "    # Add random noise to the labels - important trick!\n",
    "    labels_domain += 0.05 * tf.random.uniform(labels_domain.shape)\n",
    "\n",
    "    # Train the discriminator\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        features = feature_extractor(combined_images)\n",
    "        predictions_disc = discriminator(features)\n",
    "        # predictions = discriminator(combined_images)\n",
    "        d_loss = loss_fn(labels, predictions_disc)\n",
    "\n",
    "        features = feature_extractor(real_images)\n",
    "        predictions_clas = categorical_classifier(features)\n",
    "        # predictions = classifier(real_images)\n",
    "        c_loss = loss_fn_cls(real_label, predictions_clas)\n",
    "\n",
    "        features = feature_extractor(combined_domain)\n",
    "        predictions_domain = domain_classifier(features)\n",
    "        domain_loss = loss_fn(labels_domain, predictions_domain)\n",
    "        domain_loss = -1 * domain_loss\n",
    "\n",
    "        # fe_loss = total_loss(predictions_disc, labels, predictions_clas, real_label)\n",
    "        fe_loss = W_ADVERSARIAL * d_loss + W_CATEGORICAL * c_loss + W_DOMAIN * domain_loss\n",
    "        \n",
    "#     tf.print(fe_loss, d_loss, c_loss, domain_loss)\n",
    "\n",
    "    grads_feature_extractor = tape.gradient(fe_loss, feature_extractor.trainable_weights)\n",
    "    fe_optimizer.apply_gradients(zip(grads_feature_extractor, feature_extractor.trainable_weights))\n",
    "\n",
    "    grads_discriminator = tape.gradient(d_loss, discriminator.trainable_weights)\n",
    "    d_optimizer.apply_gradients(zip(grads_discriminator, discriminator.trainable_weights))\n",
    "\n",
    "    grads_categorical = tape.gradient(c_loss, categorical_classifier.trainable_weights)\n",
    "    c_optimizer.apply_gradients(zip(grads_categorical, categorical_classifier.trainable_weights))\n",
    "\n",
    "    grads_domain = tape.gradient(domain_loss, domain_classifier.trainable_weights)\n",
    "    domain_optimizer.apply_gradients(zip(grads_domain, domain_classifier.trainable_weights))\n",
    "\n",
    "\n",
    "\n",
    "    #################################\n",
    "\n",
    "    # Sample random points in the latent space\n",
    "    random_latent_vectors = tf.random.normal(shape=(BATCH_SIZE, latent_dim))\n",
    "    # Assemble labels that say \"all real images\"\n",
    "    misleading_labels = tf.zeros((BATCH_SIZE, 1))\n",
    "\n",
    "    # Train the generator (note that we should *not* update the weights\n",
    "    # of the discriminator)!\n",
    "    with tf.GradientTape() as tape:\n",
    "        features = feature_extractor(generator(random_latent_vectors))\n",
    "        predictions = discriminator(features)\n",
    "        # predictions = discriminator(generator(random_latent_vectors))\n",
    "        g_loss = loss_fn(misleading_labels, predictions)\n",
    "    grads = tape.gradient(g_loss, generator.trainable_weights)\n",
    "    g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "\n",
    "#     print(\"##########train step###########\")\n",
    "#     print(feature_extractor.name)\n",
    "#     print(categorical_classifier.name)\n",
    "#     print(domain_classifier.name)\n",
    "#     print(discriminator.name)\n",
    "#     print(generator.name)\n",
    "\n",
    "    c_acc_t = train_accuracy(tf.math.argmax(categorical_classifier(feature_extractor(real_images)), 1) , real_label)\n",
    "    c_acc_v = val_accuracy(tf.math.argmax(categorical_classifier(feature_extractor(test_images)), 1), test_label)\n",
    "    c_acc_target = target_accuracy(tf.math.argmax(categorical_classifier(feature_extractor(target_images)), 1), target_label)\n",
    "\n",
    "\n",
    "    return c_acc_target, c_acc_v, c_acc_t, domain_loss, c_loss, d_loss, g_loss, fe_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iPz0CM0Au3iA"
   },
   "outputs": [],
   "source": [
    "def plot_loss_values(gl_, al_, cl_, dl_, tl_):\n",
    "    x = np.arange(len(gl_))\n",
    "\n",
    "    plt.plot(x, gl_, label = \"generative loss\", linestyle=\"-.\")\n",
    "    plt.plot(x, al_, label = \"adversarial loss\", linestyle=\"-\")\n",
    "    plt.plot(x, cl_, label = \"categorical loss\", linestyle=\"--\")\n",
    "    plt.plot(x, dl_, label = \"domain loss\", linestyle=\":\")\n",
    "    plt.plot(x, tl_, label = \"total loss\", linestyle=(0, (3, 1, 1, 1)))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "va5R8-sQu5se"
   },
   "outputs": [],
   "source": [
    "def plot_acc_values(acc_source_, acc_target_, acc_source_val_):\n",
    "    x = np.arange(len(acc_source_))\n",
    "    plt.plot(x, acc_source_, label = \"source acc\", linestyle=\"-\")\n",
    "    plt.plot(x, acc_target_, label = \"target acc\", linestyle=\":\")\n",
    "    plt.plot(x, acc_source_val_, label = \"val acc\", linestyle=\"-.\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_extractor():\n",
    "    feature_extractor = tf.keras.applications.InceptionV3(\n",
    "        weights='imagenet',\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DIM),\n",
    "        include_top=False)\n",
    "\n",
    "    feature_extractor.trainable = False\n",
    "\n",
    "    feature_extractor = keras.Sequential(\n",
    "        [\n",
    "            feature_extractor,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(512, activation='relu', kernel_initializer='he_uniform'),\n",
    "\n",
    "        ],\n",
    "#         name=\"feature_extractor\",\n",
    "    )\n",
    "    \n",
    "    return feature_extractor\n",
    "    \n",
    "def create_categorical_cls():\n",
    "    \n",
    "    categorical_classifier = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(31, activation='softmax'),\n",
    "        ],\n",
    "#         name=\"categorical_classifier\",\n",
    "    )\n",
    "    \n",
    "    return categorical_classifier\n",
    "\n",
    "def create_domain_cls():\n",
    "    domain_classifier = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "            layers.Dropout(0.3),\n",
    "            GradReverse(),\n",
    "            layers.Dense(1),\n",
    "        ],\n",
    "#         name=\"domain_classifier\",\n",
    "    )\n",
    "    \n",
    "    return domain_classifier\n",
    "    \n",
    "def create_generator():\n",
    "    generator = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(latent_dim,)),\n",
    "            # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
    "            layers.Dense(8 * 8 * 128),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Reshape((8, 8, 128)),\n",
    "            layers.Conv2DTranspose(128, (4, 4), strides=(4, 4), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(128, (4, 4), strides=(4, 4), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            # layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "            # layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(3, (8, 8), padding=\"same\", activation=\"sigmoid\"),\n",
    "        ],\n",
    "#         name=\"generator\",\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "def crete_discriminator():\n",
    "    discriminator = keras.Sequential(\n",
    "        [\n",
    "            # layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "            # layers.Dropout(0.3),\n",
    "            layers.Dense(1),\n",
    "        ],\n",
    "#         name=\"discriminator\",\n",
    "    )\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 03:11:15.296211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-11-22 03:11:15.830838: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "feature_extractor1 = create_feature_extractor()\n",
    "for x, y in dataset_source.take(1):\n",
    "    features = feature_extractor1(x)\n",
    "feature_extractor1.save_weights('feature_extractor.h5')\n",
    "\n",
    "categorical_classifier1 = create_categorical_cls()\n",
    "cat_cls = categorical_classifier1(features)\n",
    "categorical_classifier1.save_weights('categorical_classifier.h5')\n",
    "\n",
    "domain_classifier1 = create_domain_cls()\n",
    "dom_cls = domain_classifier1(features)\n",
    "domain_classifier1.save_weights('domain_classifier.h5')\n",
    "\n",
    "discriminator1 = crete_discriminator()\n",
    "disc_cls = discriminator1(features)\n",
    "discriminator1.save_weights('discriminator.h5')\n",
    "\n",
    "generator1 = create_generator()\n",
    "gen_data = generator1(tf.random.normal(shape=(BATCH_SIZE, latent_dim)))\n",
    "generator1.save_weights('generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XO-wpOEAo3MD",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 03:11:23.925895: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x6dc33e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-22 03:11:23.925921: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Quadro RTX 6000, Compute Capability 7.5\n",
      "2023-11-22 03:11:23.930085: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-22 03:11:24.012961: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-22 03:11:24.076980: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f45644aa280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f45644aa280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0 W_DOMAIN:  0\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0 W_DOMAIN:  0.1\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0 W_DOMAIN:  0.3\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0 W_DOMAIN:  0.6\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0 W_DOMAIN:  0.01\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.1 W_DOMAIN:  0\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.1 W_DOMAIN:  0.1\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.1 W_DOMAIN:  0.3\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.1 W_DOMAIN:  0.6\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.1 W_DOMAIN:  0.01\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.3 W_DOMAIN:  0\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.3 W_DOMAIN:  0.1\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.3 W_DOMAIN:  0.3\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.3 W_DOMAIN:  0.6\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.3 W_DOMAIN:  0.01\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.6 W_DOMAIN:  0\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.6 W_DOMAIN:  0.1\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.6 W_DOMAIN:  0.3\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.6 W_DOMAIN:  0.6\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.6 W_DOMAIN:  0.01\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.01 W_DOMAIN:  0\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.01 W_DOMAIN:  0.1\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.01 W_DOMAIN:  0.3\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.01 W_DOMAIN:  0.6\n",
      "W_CATEGORICAL:  0.3 W_ADVERSARIAL:  0.01 W_DOMAIN:  0.01\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0 W_DOMAIN:  0\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0 W_DOMAIN:  0.1\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0 W_DOMAIN:  0.3\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0 W_DOMAIN:  0.6\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0 W_DOMAIN:  0.01\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.1 W_DOMAIN:  0\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.1 W_DOMAIN:  0.1\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.1 W_DOMAIN:  0.3\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.1 W_DOMAIN:  0.6\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.1 W_DOMAIN:  0.01\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.3 W_DOMAIN:  0\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.3 W_DOMAIN:  0.1\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.3 W_DOMAIN:  0.3\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.3 W_DOMAIN:  0.6\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.3 W_DOMAIN:  0.01\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.6 W_DOMAIN:  0\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.6 W_DOMAIN:  0.1\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.6 W_DOMAIN:  0.3\n",
      "W_CATEGORICAL:  0.6 W_ADVERSARIAL:  0.6 W_DOMAIN:  0.6\n"
     ]
    }
   ],
   "source": [
    "# W_CATEGORICAL = 0.1\n",
    "# W_ADVERSARIAL = 0\n",
    "# W_DOMAIN      = 1\n",
    "\n",
    "FinalResult = []\n",
    "\n",
    "scales = np.arange(0,1.1,.5)\n",
    "scales = [0, 0.1, 0.3, 0.6, 0.01]\n",
    "# scales = [0.1, 0.3]\n",
    "\n",
    "for W_CATEGORICAL in scales[-3:]:\n",
    "    for W_ADVERSARIAL in scales:\n",
    "        for W_DOMAIN in scales:\n",
    "            \n",
    "            feature_extractor = create_feature_extractor()\n",
    "            feature_extractor.load_weights('feature_extractor.h5')\n",
    "            for x, y in dataset_source.take(1):\n",
    "                features = feature_extractor(x)\n",
    "\n",
    "                \n",
    "            categorical_classifier = create_categorical_cls()\n",
    "            cat_cls = categorical_classifier(features)\n",
    "            categorical_classifier.load_weights('categorical_classifier.h5')\n",
    "            \n",
    "            domain_classifier = create_domain_cls()\n",
    "            dom_cls = domain_classifier(features)\n",
    "            domain_classifier.load_weights('domain_classifier.h5')\n",
    "            \n",
    "            discriminator = crete_discriminator()\n",
    "            disc_cls = discriminator(features)\n",
    "            discriminator.load_weights('discriminator.h5')\n",
    "\n",
    "            generator = create_generator()\n",
    "            gen_data = generator(tf.random.normal(shape=(BATCH_SIZE, latent_dim)))\n",
    "            generator.load_weights('generator.h5')\n",
    "            \n",
    "            \n",
    "            \n",
    "#             print(feature_extractor.name)\n",
    "#             print(categorical_classifier.name)\n",
    "#             print(domain_classifier.name)\n",
    "#             print(discriminator.name)\n",
    "#             print(generator.name)\n",
    "#             print(\"##################\")\n",
    "            \n",
    "            \n",
    "            # Instantiate one optimizer for the discriminator and another for the generator.\n",
    "            d_optimizer = keras.optimizers.Adam()\n",
    "            g_optimizer = keras.optimizers.Adam()\n",
    "            c_optimizer = keras.optimizers.Adam()\n",
    "            fe_optimizer = keras.optimizers.Adam()\n",
    "            domain_optimizer = keras.optimizers.Adam()\n",
    "            \n",
    "\n",
    "            # Instantiate a loss function.\n",
    "            loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            loss_fn_cls = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "            val_accuracy = tf.keras.metrics.Accuracy()\n",
    "            train_accuracy = tf.keras.metrics.Accuracy()\n",
    "            target_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "\n",
    "            ###################################################################\n",
    "\n",
    "            gl_, al_, cl_, dl_, tl_, acc_source_, acc_target_, acc_source_val_ = [], [], [], [], [], [], [], []\n",
    "            \n",
    "\n",
    "            for epoch in range(EPOCHS):\n",
    "\n",
    "                train_accuracy.reset_state()\n",
    "                val_accuracy.reset_state()\n",
    "                target_accuracy.reset_state()\n",
    "\n",
    "\n",
    "                for step, ((real_images, real_label), (test_images, test_label), (target_images, target_label)) in enumerate(dataset):\n",
    "                    # Train the discriminator & generator on one batch of real images.\n",
    "                    acc_target, acc_source_val, acc_source, domain_loss, categorical_loss, adversarial_loss, generative_loss, fe_loss = train_step(real_images, real_label, test_images, test_label, target_images, target_label)\n",
    "#                     acc_target, acc_source_val, acc_source, domain_loss, categorical_loss, adversarial_loss, generative_loss, fe_loss = train_step(d_optimizer, g_optimizer, c_optimizer, fe_optimizer, domain_optimizer, feature_extractor, categorical_classifier, domain_classifier, generator, discriminator, real_images, real_label, test_images, test_label, target_images, target_label)\n",
    "\n",
    "                    gl_ += [generative_loss]\n",
    "                    al_ += [adversarial_loss]\n",
    "                    cl_ += [categorical_loss]\n",
    "                    dl_ += [domain_loss]\n",
    "                    tl_ += [fe_loss]\n",
    "                    acc_source_ += [acc_source]\n",
    "                    acc_target_ += [acc_target]\n",
    "                    acc_source_val_ +=[acc_source_val]\n",
    "\n",
    "#             plot_loss_values(gl_, al_, cl_, dl_, tl_)\n",
    "#             plot_acc_values(acc_source_, acc_target_, acc_source_val_)\n",
    "            \n",
    "            tempResult = {'W_CATEGORICAL' : W_CATEGORICAL,\n",
    "                          'W_ADVERSARIAL' : W_ADVERSARIAL,\n",
    "                          'W_DOMAIN'      : W_DOMAIN,\n",
    "                          'gl_':gl_, \n",
    "                          'al_':al_, \n",
    "                          'cl_':cl_, \n",
    "                          'dl_':dl_, \n",
    "                          'tl_':tl_, \n",
    "                          'acc_source_':acc_source_, \n",
    "                          'acc_target_':acc_target_, \n",
    "                          'acc_source_val_':acc_source_val_}\n",
    "            FinalResult+=[tempResult]\n",
    "\n",
    "            # save dictionary to person_data.pkl file\n",
    "            print('W_CATEGORICAL: ', W_CATEGORICAL,\n",
    "                  'W_ADVERSARIAL: ' , W_ADVERSARIAL,\n",
    "                  'W_DOMAIN: ' , W_DOMAIN)\n",
    "            \n",
    "#             del feature_extractor\n",
    "#             del categorical_classifier\n",
    "#             del domain_classifier\n",
    "#             del generator\n",
    "#             del discriminator\n",
    "            \n",
    "#             keras.backend.clear_session()\n",
    "            \n",
    "#         break   \n",
    "#     break\n",
    "            \n",
    "with open('result.pkl', 'wb') as fp:\n",
    "    pickle.dump({'result':FinalResult}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.pkl', 'wb') as fp:\n",
    "    pickle.dump({'result':FinalResult}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Read dictionary pkl file\n",
    "with open('result.pkl', 'rb') as fp:\n",
    "    person = pickle.load(fp)\n",
    "    print('Person dictionary')\n",
    "#     print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7ZTjtqMMPSO",
    "outputId": "15dfe05b-b500-4cc8-eb25-da7d5f8559cb"
   },
   "outputs": [],
   "source": [
    "person['result'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 45\n",
    "plot_loss_values(person['result'][i]['gl_'], person['result'][i]['al_'], person['result'][i]['cl_'], person['result'][i]['dl_'], person['result'][i]['tl_'])\n",
    "plot_acc_values(person['result'][i]['acc_source_'], person['result'][i]['acc_target_'], person['result'][i]['acc_source_val_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fE8ZoAwh-e0S",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(\"W_CATEGORICAL: \", person['result'][i]['W_CATEGORICAL'])\n",
    "    print(\"W_ADVERSARIAL: \", person['result'][i]['W_ADVERSARIAL'])\n",
    "    print(\"W_DOMAIN: \", person['result'][i]['W_DOMAIN'])\n",
    "    \n",
    "    plot_loss_values(person['result'][i]['gl_'], person['result'][i]['al_'], person['result'][i]['cl_'], person['result'][i]['dl_'], person['result'][i]['tl_'])\n",
    "    plot_acc_values(person['result'][i]['acc_source_'], person['result'][i]['acc_target_'], person['result'][i]['acc_source_val_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recap_acc = person['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_records(recap_acc)\n",
    "df['gl_'] = df['gl_'].map(lambda x: x[-1].numpy())\n",
    "df['al_'] = df['al_'].map(lambda x: x[-1].numpy())\n",
    "df['cl_'] = df['cl_'].map(lambda x: x[-1].numpy())\n",
    "df['dl_'] = df['dl_'].map(lambda x: x[-1].numpy())\n",
    "df['tl_'] = df['tl_'].map(lambda x: x[-1].numpy())\n",
    "\n",
    "df['acc_source_'] = df['acc_source_'].map(lambda x: x[-1].numpy())\n",
    "df['acc_target_'] = df['acc_target_'].map(lambda x: x[-1].numpy())\n",
    "df['acc_source_val_'] = df['acc_source_val_'].map(lambda x: x[-1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.style.background_gradient(cmap ='coolwarm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['W_CATEGORICAL', 'W_ADVERSARIAL', 'W_DOMAIN','acc_source_', 'acc_target_', 'acc_source_val_']].corr().style.background_gradient(cmap ='coolwarm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['W_CATEGORICAL', 'W_ADVERSARIAL', 'W_DOMAIN','gl_', 'al_', 'cl_', 'dl_', 'tl_']].corr().style.background_gradient(cmap ='coolwarm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
