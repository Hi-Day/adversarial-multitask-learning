{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73950c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result/amazon_dslr/amazon_dslr = 0.0-0.0-0.0.pkl\n",
      "office31/amazon office31/dslr\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 73\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(DIR_SOURCE, DIR_TARGET)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# In[2]:\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# In[3]:\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDataLoader\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source, target, BATCH_SIZE\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, IMG_HEIGHT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m, IMG_WIDTH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m, IMG_DIM \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py:45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/__internal__/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf.__internal__.distribute namespace.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf.__internal__.distribute.combinations namespace.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m env\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_main_process\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/combinations.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_all_reduce_strategy\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_worker_test_base\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/multi_process_runner.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2_compat\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_worker_util\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_lib\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test_util\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/multi_process_lib.py:57\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_with_absl\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     54\u001b[0m     app\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mlambda\u001b[39;00m _: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_impl())\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAbslForkServerProcess\u001b[39;00m(_AbslProcess,\n\u001b[1;32m     60\u001b[0m                               multiprocessing\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mForkServerProcess):\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"An absl-compatible Forkserver process.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    Note: Forkserver is not available in windows.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/multi_process_lib.py:36\u001b[0m, in \u001b[0;36m_is_enabled\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_enabled\u001b[39m():\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;66;03m# Note that flags may not be parsed at this point and simply importing the\u001b[39;00m\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;66;03m# flags module causes a variety of unusual errors.\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m   tpu_args \u001b[38;5;241m=\u001b[39m [arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--tpu\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     37\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_oss() \u001b[38;5;129;01mand\u001b[39;00m tpu_args:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/multi_process_lib.py:36\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_enabled\u001b[39m():\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;66;03m# Note that flags may not be parsed at this point and simply importing the\u001b[39;00m\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;66;03m# flags module causes a variety of unusual errors.\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m   tpu_args \u001b[38;5;241m=\u001b[39m [arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;28;01mif\u001b[39;00m \u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--tpu\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     37\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_oss() \u001b[38;5;129;01mand\u001b[39;00m tpu_args:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# #!/usr/bin/env python\n",
    "# # coding: utf-8\n",
    "\n",
    "import sys\n",
    "\n",
    "# print(sys.argv[1:])\n",
    "\n",
    "sys.argv = [0, 0, 0, 0, 'amazon', 'dslr']\n",
    "\n",
    "AMAZON = \"amazon\"\n",
    "DSLR = \"dslr\"\n",
    "WEBCAM = \"webcam\"\n",
    "\n",
    "DIR_RESULT = \"result/{}_{}/\".format(sys.argv[4],sys.argv[5])\n",
    "\n",
    "DIR_AMAZON = \"office31/{}\".format(AMAZON)\n",
    "DIR_DSLR = \"office31/{}\".format(DSLR)\n",
    "DIR_WEBCAM = \"office31/{}\".format(WEBCAM)\n",
    "\n",
    "################################## config #################################\n",
    "\n",
    "# 0, 1, 2, 3, 4\n",
    "# M, N, O = sys.argv[1], sys.argv[2], sys.argv[3]\n",
    "\n",
    "DIR_SOURCE = \"office31/{}\".format(sys.argv[4])\n",
    "DIR_TARGET = \"office31/{}\".format(sys.argv[5])\n",
    "\n",
    "###########################################################################\n",
    "\n",
    "if DIR_SOURCE == DIR_AMAZON:\n",
    "    SOURCE = AMAZON\n",
    "elif DIR_SOURCE == DIR_DSLR:\n",
    "    SOURCE = DSLR\n",
    "elif DIR_SOURCE == DIR_WEBCAM:\n",
    "    SOURCE = WEBCAM\n",
    "    \n",
    "if DIR_TARGET == DIR_AMAZON:\n",
    "    SOURCE = AMAZON\n",
    "elif DIR_TARGET == DIR_DSLR:\n",
    "    SOURCE = DSLR\n",
    "elif DIR_TARGET == DIR_WEBCAM:\n",
    "    SOURCE = WEBCAM\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "IMG_DIM = 3\n",
    "\n",
    "LATENT_DIM = 128\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "scales = [0, 0.1, 0.3, 0.6, 0.01]\n",
    "\n",
    "W_CATEGORICAL = float(sys.argv[1])\n",
    "W_ADVERSARIAL = float(sys.argv[2])\n",
    "W_DOMAIN      = float(sys.argv[3])\n",
    "    \n",
    "TITLE = \"{}_{} = {}-{}-{}\".format(sys.argv[4],sys.argv[5], W_CATEGORICAL, W_ADVERSARIAL, W_DOMAIN)\n",
    "    \n",
    "print(DIR_RESULT + TITLE + '.pkl')\n",
    "print(DIR_SOURCE, DIR_TARGET)\n",
    "\n",
    "\n",
    "# # Model\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "# # Training Loop\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# with open(DIR_RESULT + TITLE + '.pkl', 'wb') as fp:\n",
    "#     pickle.dump({'result':FinalResult}, fp)\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, source, target, BATCH_SIZE=64, IMG_HEIGHT = 128, IMG_WIDTH = 128, IMG_DIM = 3):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.IMG_HEIGHT = IMG_HEIGHT\n",
    "        self.IMG_WIDTH = IMG_WIDTH\n",
    "        self.IMG_DIM = IMG_DIM\n",
    "        self.normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "    def load_source_train(self):\n",
    "        dataset_source =  tf.keras.utils.image_dataset_from_directory(\n",
    "                                self.source,\n",
    "                                validation_split=0.2,\n",
    "                                subset=\"training\",\n",
    "                                seed=123,\n",
    "                                image_size=(self.IMG_HEIGHT, self.IMG_WIDTH),\n",
    "                                batch_size=self.BATCH_SIZE)\n",
    "\n",
    "        return dataset_source.map(lambda x, y: (self.normalization_layer(x), y))\n",
    "\n",
    "\n",
    "    def load_source_validation(self):\n",
    "        dataset_source_val =  tf.keras.utils.image_dataset_from_directory(\n",
    "                                self.source,\n",
    "                                validation_split=0.2,\n",
    "                                subset=\"validation\",\n",
    "                                seed=123,\n",
    "                                image_size=(self.IMG_HEIGHT, self.IMG_WIDTH),\n",
    "                                batch_size=self.BATCH_SIZE)\n",
    "\n",
    "        return dataset_source_val.map(lambda x, y: (self.normalization_layer(x), y))\n",
    "\n",
    "    def load_target_test(self):\n",
    "        dataset_target =  tf.keras.utils.image_dataset_from_directory(\n",
    "                                self.target,\n",
    "                                seed=123,\n",
    "                                image_size=(self.IMG_HEIGHT, self.IMG_WIDTH),\n",
    "                                batch_size=self.BATCH_SIZE)\n",
    "\n",
    "        return dataset_target.map(lambda x, y: (self.normalization_layer(x), y))\n",
    "\n",
    "    def load(self):\n",
    "        return tf.data.Dataset.zip((self.load_source_train(), self.load_source_validation(), self.load_target_test()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ebea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x):\n",
    "    y = tf.identity(x)\n",
    "    def custom_grad(dy):\n",
    "        return -dy\n",
    "    return y, custom_grad\n",
    "\n",
    "class GradReverse(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class AML(tf.keras.Model):\n",
    "    \"\"\"Adeversarial Multitask Learning.\"\"\"\n",
    "\n",
    "    def __init__(self, weight_adversarial=0, weight_categorical=0, weight_domain=0):\n",
    "        super(AML, self).__init__()\n",
    "\n",
    "        self.InceptionV3 = tf.keras.applications.InceptionV3(\n",
    "                            weights='imagenet',\n",
    "                            input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DIM),\n",
    "                            include_top=False)\n",
    "\n",
    "        self.InceptionV3.trainable = False\n",
    "\n",
    "        self.feature_extractor = keras.Sequential(\n",
    "                [\n",
    "                    self.InceptionV3,\n",
    "                    layers.GlobalAveragePooling2D(),\n",
    "                    layers.Flatten(),\n",
    "                    layers.Dropout(0.5),\n",
    "                    layers.Dense(512, activation='relu', kernel_initializer='he_uniform'),\n",
    "\n",
    "                ],\n",
    "                name=\"feature_extractor\",\n",
    "            )\n",
    "\n",
    "        self.categorical_classifier = keras.Sequential(\n",
    "                [\n",
    "                    layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "                    layers.Dropout(0.3),\n",
    "                    layers.Dense(31, activation='softmax'),\n",
    "                ],\n",
    "                name=\"categorical_classifier\",\n",
    "            )\n",
    "\n",
    "        self.domain_classifier = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "                layers.Dropout(0.3),\n",
    "                GradReverse(),\n",
    "                layers.Dense(1),\n",
    "            ],\n",
    "            name=\"domain_classifier\",\n",
    "        )\n",
    "\n",
    "        self.generator = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=(LATENT_DIM,)),\n",
    "                layers.Dense(8 * 8 * 128),\n",
    "                layers.LeakyReLU(alpha=0.2),\n",
    "                layers.Reshape((8, 8, 128)),\n",
    "                layers.Conv2DTranspose(128, (4, 4), strides=(4, 4), padding=\"same\"),\n",
    "                layers.LeakyReLU(alpha=0.2),\n",
    "                layers.Conv2DTranspose(128, (4, 4), strides=(4, 4), padding=\"same\"),\n",
    "                layers.LeakyReLU(alpha=0.2),\n",
    "                layers.Conv2D(3, (8, 8), padding=\"same\", activation=\"sigmoid\"),\n",
    "            ],\n",
    "            name=\"generator\",\n",
    "        )\n",
    "\n",
    "        self.discriminator = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(1),\n",
    "            ],\n",
    "            name=\"discriminator\",\n",
    "        )\n",
    "\n",
    "        self.weight_categorical = weight_categorical\n",
    "        self.weight_adversarial = weight_adversarial\n",
    "        self.weight_domain      = weight_domain\n",
    "\n",
    "        self.d_optimizer = keras.optimizers.Adam()\n",
    "        self.g_optimizer = keras.optimizers.Adam()\n",
    "        self.c_optimizer = keras.optimizers.Adam()\n",
    "        self.fe_optimizer = keras.optimizers.Adam()\n",
    "        self.domain_optimizer = keras.optimizers.Adam()\n",
    "\n",
    "        self.val_accuracy = tf.keras.metrics.Accuracy()\n",
    "        self.train_accuracy = tf.keras.metrics.Accuracy()\n",
    "        self.target_accuracy = tf.keras.metrics.Accuracy()\n",
    "        \n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.loss_fn_cls = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "\n",
    "\n",
    "    def sample(self):\n",
    "        random_latent_vectors = tf.random.normal(shape=(BATCH_SIZE, LATENT_DIM))\n",
    "        data = self.generator(random_latent_vectors)\n",
    "        features = self.feature_extractor(data)\n",
    "        cat_cls = self.categorical_classifier(features)\n",
    "        dom_cls = self.domain_classifier(features)\n",
    "        dis_cls = self.discriminator(features)\n",
    "\n",
    "        return cat_cls, dom_cls, dis_cls\n",
    "\n",
    "    def predict_domain(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.domain_classifier(features)\n",
    "\n",
    "    def predict_category(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.categorical_classifier(features)\n",
    "\n",
    "    def predict_adversarial(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.discriminator(features)\n",
    "\n",
    "    def generate_data(self):\n",
    "        random_latent_vectors = tf.random.normal(shape=(BATCH_SIZE, LATENT_DIM))\n",
    "        return self.generator(random_latent_vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def train_step(model, real_images, real_label, test_images, test_label, target_images, target_label):\n",
    "\n",
    "    #adversarial data\n",
    "    generated_images = model.generate_data()\n",
    "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "#     combined_labels = tf.concat([tf.ones((BATCH_SIZE, 1)), tf.zeros((BATCH_SIZE, 1))], axis=0)\n",
    "    combined_labels = tf.concat([tf.ones((BATCH_SIZE, 1)), tf.zeros((real_images.shape[0], 1))], axis=0)\n",
    "    combined_labels += 0.05 * tf.random.uniform(combined_labels.shape)\n",
    "\n",
    "    #domain\n",
    "    combined_domain = tf.concat([target_images, real_images], axis=0)\n",
    "#     labels_domain = tf.concat([tf.ones((BATCH_SIZE, 1)), tf.zeros((BATCH_SIZE, 1))], axis=0)\n",
    "    labels_domain = tf.concat([tf.ones((target_images.shape[0], 1)), tf.zeros((real_images.shape[0], 1))], axis=0)\n",
    "    labels_domain += 0.05 * tf.random.uniform(labels_domain.shape)\n",
    "\n",
    "    # Train the discriminator, cat_classifier, dom_classifier\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "        predictions_disc = model.predict_adversarial(combined_images)\n",
    "        d_loss = model.loss_fn(combined_labels, predictions_disc)\n",
    "\n",
    "        predictions_clas = model.predict_category(real_images)\n",
    "        c_loss = model.loss_fn_cls(real_label, predictions_clas)\n",
    "\n",
    "        predictions_domain = model.predict_domain(combined_domain)\n",
    "        domain_loss = -1 * model.loss_fn(labels_domain, predictions_domain)\n",
    "        # domain_loss = -1 * domain_loss\n",
    "\n",
    "        fe_loss = model.weight_adversarial * d_loss + model.weight_categorical * c_loss + model.weight_domain * domain_loss\n",
    "\n",
    "    grads_feature_extractor = tape.gradient(fe_loss, model.feature_extractor.trainable_weights)\n",
    "    model.fe_optimizer.apply_gradients(zip(grads_feature_extractor, model.feature_extractor.trainable_weights))\n",
    "\n",
    "    grads_discriminator = tape.gradient(d_loss, model.discriminator.trainable_weights)\n",
    "    model.d_optimizer.apply_gradients(zip(grads_discriminator, model.discriminator.trainable_weights))\n",
    "\n",
    "    grads_categorical = tape.gradient(c_loss, model.categorical_classifier.trainable_weights)\n",
    "    model.c_optimizer.apply_gradients(zip(grads_categorical, model.categorical_classifier.trainable_weights))\n",
    "\n",
    "    grads_domain = tape.gradient(domain_loss, model.domain_classifier.trainable_weights)\n",
    "    model.domain_optimizer.apply_gradients(zip(grads_domain, model.domain_classifier.trainable_weights))\n",
    "\n",
    "    # Train generator\n",
    "    misleading_labels = tf.zeros((BATCH_SIZE, 1))\n",
    "    with tf.GradientTape() as tape:\n",
    "        generated_images = model.generate_data()\n",
    "        predictions = model.predict_adversarial(generated_images)\n",
    "        g_loss = model.loss_fn(misleading_labels, predictions)\n",
    "    grads = tape.gradient(g_loss, model.generator.trainable_weights)\n",
    "    model.g_optimizer.apply_gradients(zip(grads, model.generator.trainable_weights))\n",
    "\n",
    "    c_acc_t = model.train_accuracy(tf.math.argmax(model.predict_category(real_images), 1) , real_label)\n",
    "    c_acc_v = model.val_accuracy(tf.math.argmax(model.predict_category(test_images), 1), test_label)\n",
    "    c_acc_target = model.target_accuracy(tf.math.argmax(model.predict_category(target_images), 1), target_label)\n",
    "\n",
    "    return c_acc_target, c_acc_v, c_acc_t, domain_loss, c_loss, d_loss, g_loss, fe_loss\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "dataset = DataLoader(DIR_SOURCE, DIR_TARGET).load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7467192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# @tf.function\n",
    "def train(model, dataset, EPOCHS):\n",
    "\n",
    "    gl_, al_, cl_, dl_, tl_, acc_source_, acc_target_, acc_source_val_ = [], [], [], [], [], [], [], []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        model.train_accuracy.reset_state()\n",
    "        model.val_accuracy.reset_state()\n",
    "        model.target_accuracy.reset_state()\n",
    "        \n",
    "        for step, ((real_images, real_label), (test_images, test_label), (target_images, target_label)) in enumerate(dataset):\n",
    "            \n",
    "            \n",
    "            acc_target, acc_source_val, acc_source, domain_loss, categorical_loss, adversarial_loss, generative_loss, fe_loss = train_step(model, real_images, real_label, test_images, test_label, target_images, target_label)\n",
    "            \n",
    "            \n",
    "            gl_ += [generative_loss]\n",
    "            al_ += [adversarial_loss]\n",
    "            cl_ += [categorical_loss]\n",
    "            dl_ += [domain_loss]\n",
    "            tl_ += [fe_loss]\n",
    "            acc_source_ += [acc_source]\n",
    "            acc_target_ += [acc_target]\n",
    "            acc_source_val_ +=[acc_source_val]\n",
    "            \n",
    "        done = time.time()\n",
    "        elapsed = done - start\n",
    "        \n",
    "        if(epoch % 10 == 0):\n",
    "            print(\"Epoch {} - Time {}\".format(epoch, elapsed))\n",
    "\n",
    "    return gl_, al_, cl_, dl_, tl_, acc_source_, acc_target_, acc_source_val_\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_values(gl_, al_, cl_, dl_, tl_):\n",
    "    x = np.arange(len(gl_))\n",
    "\n",
    "    plt.plot(x, gl_, label = \"generative loss\", linestyle=\"-.\")\n",
    "    plt.plot(x, al_, label = \"adversarial loss\", linestyle=\"-\")\n",
    "    plt.plot(x, cl_, label = \"categorical loss\", linestyle=\"--\")\n",
    "    plt.plot(x, dl_, label = \"domain loss\", linestyle=\":\")\n",
    "    plt.plot(x, tl_, label = \"total loss\", linestyle=(0, (3, 1, 1, 1)))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def plot_acc_values(acc_source_, acc_target_, acc_source_val_):\n",
    "    x = np.arange(len(acc_source_))\n",
    "    plt.plot(x, acc_source_, label = \"source acc\", linestyle=\"-\")\n",
    "    plt.plot(x, acc_target_, label = \"target acc\", linestyle=\":\")\n",
    "    plt.plot(x, acc_source_val_, label = \"val acc\", linestyle=\"-.\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb81748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "FinalResult = []\n",
    "            \n",
    "model = AML(weight_adversarial=W_ADVERSARIAL, weight_categorical=W_CATEGORICAL, weight_domain=W_DOMAIN)\n",
    "model.sample()\n",
    "\n",
    "print(TITLE)\n",
    "\n",
    "gl_, al_, cl_, dl_, tl_, acc_source_, acc_target_, acc_source_val_ = train(model, dataset, EPOCHS)\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "tempResult = {'W_CATEGORICAL' : W_CATEGORICAL,\n",
    "              'W_ADVERSARIAL' : W_ADVERSARIAL,\n",
    "              'W_DOMAIN'      : W_DOMAIN,\n",
    "              'gl_':gl_, \n",
    "              'al_':al_, \n",
    "              'cl_':cl_, \n",
    "              'dl_':-1 * dl_, \n",
    "              'tl_':tl_, \n",
    "              'acc_source_':acc_source_, \n",
    "              'acc_target_':acc_target_, \n",
    "              'acc_source_val_':acc_source_val_}\n",
    "\n",
    "FinalResult += [tempResult]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1611508e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f6df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2596684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c739b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f10590",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_values(gl_, al_, cl_, dl_, tl_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
