{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0JHVsAKBu1e"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YO7tYct5Bqcc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 03:24:08.864983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-08 03:24:08.990336: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-08 03:24:09.516524: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-08 03:24:09.516587: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-08 03:24:09.516593: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import clone_model\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWAyTR8EVA-f"
   },
   "outputs": [],
   "source": [
    "TITLE = \"Amazon_Webcam_1\"\n",
    "N = 1\n",
    "\n",
    "DIR_AMAZON = \"office31/amazon\"\n",
    "DIR_DSLR = \"office31/dslr\"\n",
    "DIR_WEBCAM = \"office31/webcam\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "IMG_DIM = 3\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "# W_CATEGORICAL = 0.1\n",
    "# W_ADVERSARIAL = 0\n",
    "# W_DOMAIN      = 1\n",
    "\n",
    "SOURCE = DIR_AMAZON\n",
    "TARGET = DIR_WEBCAM\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "dataset_source = tf.keras.utils.image_dataset_from_directory(\n",
    "  SOURCE,                                                     # change DIR according to the dataset\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "dataset_source_val = tf.keras.utils.image_dataset_from_directory(\n",
    "  SOURCE,                                                     # change DIR according to the dataset\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "dataset_target = tf.keras.utils.image_dataset_from_directory(\n",
    "  TARGET,                                                     # change DIR according to the dataset\n",
    "  seed=123,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "dataset_source = dataset_source.map(lambda x, y: (normalization_layer(x), y))\n",
    "dataset_source_val = dataset_source_val.map(lambda x, y: (normalization_layer(x), y))\n",
    "dataset_target = dataset_target.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "dataset = tf.data.Dataset.zip((dataset_source, dataset_source_val, dataset_target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6tnywK2AgHV"
   },
   "source": [
    "# Preparation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_d6iVg1TKomt"
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def grad_reverse(x):\n",
    "    y = tf.identity(x)\n",
    "    def custom_grad(dy):\n",
    "        return -dy\n",
    "    return y, custom_grad\n",
    "\n",
    "class GradReverse(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @tf.function\n",
    "def train_step(real_images, real_label, test_images, test_label, target_images, target_label):\n",
    "# def train_step(d_optimizer, g_optimizer, c_optimizer, fe_optimizer, domain_optimizer, feature_extractor, categorical_classifier, domain_classifier, generator, discriminator, real_images, real_label, test_images, test_label, target_images, target_label):\n",
    "    # Sample random points in the latent space\n",
    "    random_latent_vectors = tf.random.normal(shape=(BATCH_SIZE, latent_dim))\n",
    "    # Decode them to fake images\n",
    "    generated_images = generator(random_latent_vectors)\n",
    "    # Combine them with real images\n",
    "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "    # Assemble labels discriminating real from fake images\n",
    "    labels = tf.concat(\n",
    "        [tf.ones((BATCH_SIZE, 1)), tf.zeros((real_images.shape[0], 1))], axis=0\n",
    "    )\n",
    "    # Add random noise to the labels - important trick!\n",
    "    labels += 0.05 * tf.random.uniform(labels.shape)\n",
    "\n",
    "    combined_domain = tf.concat([target_images, real_images], axis=0)\n",
    "\n",
    "    # Assemble labels classifying target from source images\n",
    "    labels_domain = tf.concat(\n",
    "        [tf.ones((target_images.shape[0], 1)), tf.zeros((real_images.shape[0], 1))], axis=0\n",
    "    )\n",
    "    # Add random noise to the labels - important trick!\n",
    "    labels_domain += 0.05 * tf.random.uniform(labels_domain.shape)\n",
    "\n",
    "    # Train the discriminator\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        features = feature_extractor(combined_images)\n",
    "        predictions_disc = discriminator(features)\n",
    "        # predictions = discriminator(combined_images)\n",
    "        d_loss = loss_fn(labels, predictions_disc)\n",
    "\n",
    "        features = feature_extractor(real_images)\n",
    "        predictions_clas = categorical_classifier(features)\n",
    "        # predictions = classifier(real_images)\n",
    "        c_loss = loss_fn_cls(real_label, predictions_clas)\n",
    "\n",
    "        features = feature_extractor(combined_domain)\n",
    "        predictions_domain = domain_classifier(features)\n",
    "        domain_loss = loss_fn(labels_domain, predictions_domain)\n",
    "        domain_loss = -1 * domain_loss\n",
    "\n",
    "        # fe_loss = total_loss(predictions_disc, labels, predictions_clas, real_label)\n",
    "        fe_loss = W_ADVERSARIAL * d_loss + W_CATEGORICAL * c_loss + W_DOMAIN * domain_loss\n",
    "        \n",
    "#     tf.print(fe_loss, d_loss, c_loss, domain_loss)\n",
    "\n",
    "    grads_feature_extractor = tape.gradient(fe_loss, feature_extractor.trainable_weights)\n",
    "    fe_optimizer.apply_gradients(zip(grads_feature_extractor, feature_extractor.trainable_weights))\n",
    "\n",
    "    grads_discriminator = tape.gradient(d_loss, discriminator.trainable_weights)\n",
    "    d_optimizer.apply_gradients(zip(grads_discriminator, discriminator.trainable_weights))\n",
    "\n",
    "    grads_categorical = tape.gradient(c_loss, categorical_classifier.trainable_weights)\n",
    "    c_optimizer.apply_gradients(zip(grads_categorical, categorical_classifier.trainable_weights))\n",
    "\n",
    "    grads_domain = tape.gradient(domain_loss, domain_classifier.trainable_weights)\n",
    "    domain_optimizer.apply_gradients(zip(grads_domain, domain_classifier.trainable_weights))\n",
    "\n",
    "\n",
    "\n",
    "    #################################\n",
    "\n",
    "    # Sample random points in the latent space\n",
    "    random_latent_vectors = tf.random.normal(shape=(BATCH_SIZE, latent_dim))\n",
    "    # Assemble labels that say \"all real images\"\n",
    "    misleading_labels = tf.zeros((BATCH_SIZE, 1))\n",
    "\n",
    "    # Train the generator (note that we should *not* update the weights\n",
    "    # of the discriminator)!\n",
    "    with tf.GradientTape() as tape:\n",
    "        features = feature_extractor(generator(random_latent_vectors))\n",
    "        predictions = discriminator(features)\n",
    "        # predictions = discriminator(generator(random_latent_vectors))\n",
    "        g_loss = loss_fn(misleading_labels, predictions)\n",
    "    grads = tape.gradient(g_loss, generator.trainable_weights)\n",
    "    g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "\n",
    "#     print(\"##########train step###########\")\n",
    "#     print(feature_extractor.name)\n",
    "#     print(categorical_classifier.name)\n",
    "#     print(domain_classifier.name)\n",
    "#     print(discriminator.name)\n",
    "#     print(generator.name)\n",
    "\n",
    "    c_acc_t = train_accuracy(tf.math.argmax(categorical_classifier(feature_extractor(real_images)), 1) , real_label)\n",
    "    c_acc_v = val_accuracy(tf.math.argmax(categorical_classifier(feature_extractor(test_images)), 1), test_label)\n",
    "    c_acc_target = target_accuracy(tf.math.argmax(categorical_classifier(feature_extractor(target_images)), 1), target_label)\n",
    "\n",
    "\n",
    "    return c_acc_target, c_acc_v, c_acc_t, domain_loss, c_loss, d_loss, g_loss, fe_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iPz0CM0Au3iA"
   },
   "outputs": [],
   "source": [
    "def plot_loss_values(gl_, al_, cl_, dl_, tl_):\n",
    "    x = np.arange(len(gl_))\n",
    "\n",
    "    plt.plot(x, gl_, label = \"generative loss\", linestyle=\"-.\")\n",
    "    plt.plot(x, al_, label = \"adversarial loss\", linestyle=\"-\")\n",
    "    plt.plot(x, cl_, label = \"categorical loss\", linestyle=\"--\")\n",
    "    plt.plot(x, dl_, label = \"domain loss\", linestyle=\":\")\n",
    "    plt.plot(x, tl_, label = \"total loss\", linestyle=(0, (3, 1, 1, 1)))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "va5R8-sQu5se"
   },
   "outputs": [],
   "source": [
    "def plot_acc_values(acc_source_, acc_target_, acc_source_val_):\n",
    "    x = np.arange(len(acc_source_))\n",
    "    plt.plot(x, acc_source_, label = \"source acc\", linestyle=\"-\")\n",
    "    plt.plot(x, acc_target_, label = \"target acc\", linestyle=\":\")\n",
    "    plt.plot(x, acc_source_val_, label = \"val acc\", linestyle=\"-.\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_extractor():\n",
    "    feature_extractor = tf.keras.applications.InceptionV3(\n",
    "        weights='imagenet',\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DIM),\n",
    "        include_top=False)\n",
    "\n",
    "    feature_extractor.trainable = False\n",
    "\n",
    "    feature_extractor = keras.Sequential(\n",
    "        [\n",
    "            feature_extractor,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(512, activation='relu', kernel_initializer='he_uniform'),\n",
    "\n",
    "        ],\n",
    "#         name=\"feature_extractor\",\n",
    "    )\n",
    "    \n",
    "    return feature_extractor\n",
    "    \n",
    "def create_categorical_cls():\n",
    "    \n",
    "    categorical_classifier = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(31, activation='softmax'),\n",
    "        ],\n",
    "#         name=\"categorical_classifier\",\n",
    "    )\n",
    "    \n",
    "    return categorical_classifier\n",
    "\n",
    "def create_domain_cls():\n",
    "    domain_classifier = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "            layers.Dropout(0.3),\n",
    "            GradReverse(),\n",
    "            layers.Dense(1),\n",
    "        ],\n",
    "#         name=\"domain_classifier\",\n",
    "    )\n",
    "    \n",
    "    return domain_classifier\n",
    "    \n",
    "def create_generator():\n",
    "    generator = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(latent_dim,)),\n",
    "            # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
    "            layers.Dense(8 * 8 * 128),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Reshape((8, 8, 128)),\n",
    "            layers.Conv2DTranspose(128, (4, 4), strides=(4, 4), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(128, (4, 4), strides=(4, 4), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            # layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "            # layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(3, (8, 8), padding=\"same\", activation=\"sigmoid\"),\n",
    "        ],\n",
    "#         name=\"generator\",\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "def crete_discriminator():\n",
    "    discriminator = keras.Sequential(\n",
    "        [\n",
    "            # layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "            # layers.Dropout(0.3),\n",
    "            layers.Dense(1),\n",
    "        ],\n",
    "#         name=\"discriminator\",\n",
    "    )\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 03:24:15.435645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-01-08 03:24:15.963037: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "feature_extractor1 = create_feature_extractor()\n",
    "for x, y in dataset_source.take(1):\n",
    "    features = feature_extractor1(x)\n",
    "feature_extractor1.save_weights('feature_extractor.h5')\n",
    "\n",
    "categorical_classifier1 = create_categorical_cls()\n",
    "cat_cls = categorical_classifier1(features)\n",
    "categorical_classifier1.save_weights('categorical_classifier.h5')\n",
    "\n",
    "domain_classifier1 = create_domain_cls()\n",
    "dom_cls = domain_classifier1(features)\n",
    "domain_classifier1.save_weights('domain_classifier.h5')\n",
    "\n",
    "discriminator1 = crete_discriminator()\n",
    "disc_cls = discriminator1(features)\n",
    "discriminator1.save_weights('discriminator.h5')\n",
    "\n",
    "generator1 = create_generator()\n",
    "gen_data = generator1(tf.random.normal(shape=(BATCH_SIZE, latent_dim)))\n",
    "generator1.save_weights('generator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XO-wpOEAo3MD",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_CATEGORICAL:  0 W_ADVERSARIAL:  0 W_DOMAIN:  0\n",
      "feature_extractor created\n",
      "categorical_classifier created\n",
      "categorical_classifier created\n",
      "discriminator created\n",
      "generator created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 03:24:24.188412: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x6c366a10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-08 03:24:24.188437: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Quadro RTX 6000, Compute Capability 7.5\n",
      "2024-01-08 03:24:24.192795: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-08 03:24:24.266434: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-08 03:24:24.330508: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f46bc5b6160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f46bc5b6160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch: 0 === 19.195128202438354\n",
      "Epoch: 10 === 12.43247389793396\n",
      "Epoch: 20 === 12.691322326660156\n",
      "Epoch: 30 === 12.306549072265625\n",
      "Epoch: 40 === 12.877663135528564\n",
      "Epoch: 50 === 12.588879346847534\n",
      "Epoch: 60 === 12.446516990661621\n",
      "Epoch: 70 === 12.754403352737427\n",
      "Epoch: 80 === 14.117453575134277\n",
      "Epoch: 90 === 12.48715329170227\n",
      "W_CATEGORICAL:  0 W_ADVERSARIAL:  0 W_DOMAIN:  0.1\n",
      "feature_extractor created\n",
      "categorical_classifier created\n",
      "categorical_classifier created\n",
      "discriminator created\n",
      "generator created\n",
      "Epoch: 0 === 13.827412605285645\n",
      "Epoch: 10 === 14.021841526031494\n",
      "Epoch: 20 === 12.541552305221558\n",
      "Epoch: 30 === 12.752264738082886\n",
      "Epoch: 40 === 12.866302967071533\n",
      "Epoch: 50 === 12.427413702011108\n",
      "Epoch: 60 === 12.803077459335327\n",
      "Epoch: 70 === 12.642952680587769\n",
      "Epoch: 80 === 12.750659465789795\n",
      "Epoch: 90 === 12.51344633102417\n",
      "W_CATEGORICAL:  0 W_ADVERSARIAL:  0 W_DOMAIN:  0.3\n",
      "feature_extractor created\n",
      "categorical_classifier created\n",
      "categorical_classifier created\n",
      "discriminator created\n",
      "generator created\n",
      "Epoch: 0 === 14.094756841659546\n",
      "Epoch: 10 === 12.502462387084961\n",
      "Epoch: 20 === 12.69543170928955\n",
      "Epoch: 30 === 12.814156293869019\n",
      "Epoch: 40 === 12.418413400650024\n",
      "Epoch: 50 === 14.160793542861938\n",
      "Epoch: 60 === 12.716638326644897\n",
      "Epoch: 70 === 12.387544393539429\n",
      "Epoch: 80 === 12.5845468044281\n",
      "Epoch: 90 === 12.676199913024902\n",
      "W_CATEGORICAL:  0 W_ADVERSARIAL:  0 W_DOMAIN:  0.6\n",
      "feature_extractor created\n",
      "categorical_classifier created\n",
      "categorical_classifier created\n",
      "discriminator created\n",
      "generator created\n",
      "Epoch: 0 === 13.997186660766602\n",
      "Epoch: 10 === 12.796830892562866\n",
      "Epoch: 20 === 12.819340229034424\n",
      "Epoch: 30 === 12.86245608329773\n",
      "Epoch: 40 === 12.878358840942383\n",
      "Epoch: 50 === 12.801722764968872\n",
      "Epoch: 60 === 12.513407468795776\n",
      "Epoch: 70 === 12.668656349182129\n",
      "Epoch: 80 === 12.65864896774292\n",
      "Epoch: 90 === 12.697974920272827\n",
      "W_CATEGORICAL:  0 W_ADVERSARIAL:  0 W_DOMAIN:  0.01\n",
      "feature_extractor created\n",
      "categorical_classifier created\n",
      "categorical_classifier created\n",
      "discriminator created\n",
      "generator created\n",
      "Epoch: 0 === 14.423048973083496\n",
      "Epoch: 10 === 12.359988689422607\n",
      "Epoch: 20 === 12.674477577209473\n",
      "Epoch: 30 === 12.653481721878052\n",
      "Epoch: 40 === 12.867858171463013\n",
      "Epoch: 50 === 12.67960524559021\n",
      "Epoch: 60 === 12.826531648635864\n",
      "Epoch: 70 === 12.444159984588623\n"
     ]
    }
   ],
   "source": [
    "# W_CATEGORICAL = 0.1\n",
    "# W_ADVERSARIAL = 0\n",
    "# W_DOMAIN      = 1\n",
    "\n",
    "FinalResult = []\n",
    "\n",
    "# scales = np.arange(0,1.1,.5)\n",
    "scales = [0, 0.1, 0.3, 0.6, 0.01]\n",
    "# scales = [0.1, 0.3]\n",
    "\n",
    "for W_CATEGORICAL in scales[N-1:N]:\n",
    "    for W_ADVERSARIAL in scales:\n",
    "        for W_DOMAIN in scales:\n",
    "            \n",
    "            # save dictionary to person_data.pkl file\n",
    "            print('W_CATEGORICAL: ', W_CATEGORICAL,\n",
    "                  'W_ADVERSARIAL: ' , W_ADVERSARIAL,\n",
    "                  'W_DOMAIN: ' , W_DOMAIN)\n",
    "            \n",
    "            feature_extractor = create_feature_extractor()\n",
    "            feature_extractor.load_weights('feature_extractor.h5')\n",
    "            for x, y in dataset_source.take(1):\n",
    "                features = feature_extractor(x)\n",
    "\n",
    "            print(\"feature_extractor created\")\n",
    "                \n",
    "            categorical_classifier = create_categorical_cls()\n",
    "            cat_cls = categorical_classifier(features)\n",
    "            categorical_classifier.load_weights('categorical_classifier.h5')\n",
    "            \n",
    "            print(\"categorical_classifier created\")\n",
    "            \n",
    "            domain_classifier = create_domain_cls()\n",
    "            dom_cls = domain_classifier(features)\n",
    "            domain_classifier.load_weights('domain_classifier.h5')\n",
    "            \n",
    "            print(\"categorical_classifier created\")\n",
    "            \n",
    "            discriminator = crete_discriminator()\n",
    "            disc_cls = discriminator(features)\n",
    "            discriminator.load_weights('discriminator.h5')\n",
    "            \n",
    "            print(\"discriminator created\")\n",
    "            \n",
    "            generator = create_generator()\n",
    "            gen_data = generator(tf.random.normal(shape=(BATCH_SIZE, latent_dim)))\n",
    "            generator.load_weights('generator.h5')\n",
    "            \n",
    "            print(\"generator created\")\n",
    "            \n",
    "#             print(feature_extractor.name)\n",
    "#             print(categorical_classifier.name)\n",
    "#             print(domain_classifier.name)\n",
    "#             print(discriminator.name)\n",
    "#             print(generator.name)\n",
    "#             print(\"##################\")\n",
    "            \n",
    "            \n",
    "            # Instantiate one optimizer for the discriminator and another for the generator.\n",
    "            d_optimizer = keras.optimizers.Adam()\n",
    "            g_optimizer = keras.optimizers.Adam()\n",
    "            c_optimizer = keras.optimizers.Adam()\n",
    "            fe_optimizer = keras.optimizers.Adam()\n",
    "            domain_optimizer = keras.optimizers.Adam()\n",
    "            \n",
    "\n",
    "            # Instantiate a loss function.\n",
    "            loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            loss_fn_cls = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "            val_accuracy = tf.keras.metrics.Accuracy()\n",
    "            train_accuracy = tf.keras.metrics.Accuracy()\n",
    "            target_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "\n",
    "            ###################################################################\n",
    "\n",
    "            gl_, al_, cl_, dl_, tl_, acc_source_, acc_target_, acc_source_val_ = [], [], [], [], [], [], [], []\n",
    "            \n",
    "\n",
    "            for epoch in range(EPOCHS):\n",
    "\n",
    "                train_accuracy.reset_state()\n",
    "                val_accuracy.reset_state()\n",
    "                target_accuracy.reset_state()\n",
    "                \n",
    "                start = time.time()\n",
    "                \n",
    "                for step, ((real_images, real_label), (test_images, test_label), (target_images, target_label)) in enumerate(dataset):\n",
    "                    # Train the discriminator & generator on one batch of real images.\n",
    "                    acc_target, acc_source_val, acc_source, domain_loss, categorical_loss, adversarial_loss, generative_loss, fe_loss = train_step(real_images, real_label, test_images, test_label, target_images, target_label)\n",
    "#                     acc_target, acc_source_val, acc_source, domain_loss, categorical_loss, adversarial_loss, generative_loss, fe_loss = train_step(d_optimizer, g_optimizer, c_optimizer, fe_optimizer, domain_optimizer, feature_extractor, categorical_classifier, domain_classifier, generator, discriminator, real_images, real_label, test_images, test_label, target_images, target_label)\n",
    "\n",
    "                    gl_ += [generative_loss]\n",
    "                    al_ += [adversarial_loss]\n",
    "                    cl_ += [categorical_loss]\n",
    "                    dl_ += [domain_loss]\n",
    "                    tl_ += [fe_loss]\n",
    "                    acc_source_ += [acc_source]\n",
    "                    acc_target_ += [acc_target]\n",
    "                    acc_source_val_ +=[acc_source_val]\n",
    "                \n",
    "                done = time.time()\n",
    "                elapsed = done - start\n",
    "                \n",
    "                if epoch % 10 == 0:\n",
    "                    print(\"Epoch: \" + str(epoch) + \" === \" + str(elapsed))\n",
    "\n",
    "#             plot_loss_values(gl_, al_, cl_, dl_, tl_)\n",
    "#             plot_acc_values(acc_source_, acc_target_, acc_source_val_)\n",
    "            \n",
    "            tempResult = {'W_CATEGORICAL' : W_CATEGORICAL,\n",
    "                          'W_ADVERSARIAL' : W_ADVERSARIAL,\n",
    "                          'W_DOMAIN'      : W_DOMAIN,\n",
    "                          'gl_':gl_, \n",
    "                          'al_':al_, \n",
    "                          'cl_':cl_, \n",
    "                          'dl_':dl_, \n",
    "                          'tl_':tl_, \n",
    "                          'acc_source_':acc_source_, \n",
    "                          'acc_target_':acc_target_, \n",
    "                          'acc_source_val_':acc_source_val_}\n",
    "            FinalResult+=[tempResult]\n",
    "\n",
    "            \n",
    "            with open( TITLE + ' result.pkl', 'wb') as fp:\n",
    "                pickle.dump({'result':FinalResult}, fp)\n",
    "#             del feature_extractor\n",
    "#             del categorical_classifier\n",
    "#             del domain_classifier\n",
    "#             del generator\n",
    "#             del discriminator\n",
    "            \n",
    "#             keras.backend.clear_session()\n",
    "            \n",
    "#         break   \n",
    "#     break\n",
    "            \n",
    "# with open('result.pkl', 'wb') as fp:\n",
    "#     pickle.dump({'result':FinalResult}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'time' (built-in)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TITLE + ' result.pkl', 'wb') as fp:\n",
    "    pickle.dump({'result':FinalResult}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Read dictionary pkl file\n",
    "with open(TITLE + ' result.pkl', 'rb') as fp:\n",
    "    person = pickle.load(fp)\n",
    "    print('Person dictionary')\n",
    "#     print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7ZTjtqMMPSO",
    "outputId": "15dfe05b-b500-4cc8-eb25-da7d5f8559cb"
   },
   "outputs": [],
   "source": [
    "person['result'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plot_loss_values(person['result'][i]['gl_'], person['result'][i]['al_'], person['result'][i]['cl_'], person['result'][i]['dl_'], person['result'][i]['tl_'])\n",
    "plot_acc_values(person['result'][i]['acc_source_'], person['result'][i]['acc_target_'], person['result'][i]['acc_source_val_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fE8ZoAwh-e0S",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(\"W_CATEGORICAL: \", person['result'][i]['W_CATEGORICAL'])\n",
    "    print(\"W_ADVERSARIAL: \", person['result'][i]['W_ADVERSARIAL'])\n",
    "    print(\"W_DOMAIN: \", person['result'][i]['W_DOMAIN'])\n",
    "    \n",
    "    plot_loss_values(person['result'][i]['gl_'], person['result'][i]['al_'], person['result'][i]['cl_'], person['result'][i]['dl_'], person['result'][i]['tl_'])\n",
    "    plot_acc_values(person['result'][i]['acc_source_'], person['result'][i]['acc_target_'], person['result'][i]['acc_source_val_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recap_acc = person['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_records(recap_acc)\n",
    "df['gl_'] = df['gl_'].map(lambda x: x[-1].numpy())\n",
    "df['al_'] = df['al_'].map(lambda x: x[-1].numpy())\n",
    "df['cl_'] = df['cl_'].map(lambda x: x[-1].numpy())\n",
    "df['dl_'] = df['dl_'].map(lambda x: x[-1].numpy())\n",
    "df['tl_'] = df['tl_'].map(lambda x: x[-1].numpy())\n",
    "\n",
    "df['acc_source_'] = df['acc_source_'].map(lambda x: x[-1].numpy())\n",
    "df['acc_target_'] = df['acc_target_'].map(lambda x: x[-1].numpy())\n",
    "df['acc_source_val_'] = df['acc_source_val_'].map(lambda x: x[-1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.style.background_gradient(cmap ='coolwarm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['W_CATEGORICAL', 'W_ADVERSARIAL', 'W_DOMAIN','acc_source_', 'acc_target_', 'acc_source_val_']].corr().style.background_gradient(cmap ='coolwarm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['W_CATEGORICAL', 'W_ADVERSARIAL', 'W_DOMAIN','gl_', 'al_', 'cl_', 'dl_', 'tl_']].corr().style.background_gradient(cmap ='coolwarm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
